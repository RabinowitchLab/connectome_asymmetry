{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import itertools as it\n",
    "import json\n",
    "from collections import Counter\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import platform\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to folder where all the files are stored\n",
    "folder_path = 'C:/Users/varunb/Dropbox/IR_Lab/Asymmetry_Computational/Asymmetry_elegans/Final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' small functions used throughout the code'''\n",
    "def return_contra(neuron):\n",
    "    ''' for any string ending in L/R,\n",
    "    a new string ending with R/L is returned '''\n",
    "    if neuron not in ['PQR','PVR','AVL','RIR','AQR']:\n",
    "        if neuron.endswith('L'):\n",
    "            return(neuron[:-1]+'R')\n",
    "        elif neuron.endswith('R'):\n",
    "            return(neuron[:-1]+'L')\n",
    "        else:\n",
    "            return(neuron)\n",
    "    else:\n",
    "        return(neuron)\n",
    "rc = return_contra\n",
    "def coinToss():\n",
    "        flip = random.choice([0,1])\n",
    "        if flip == 0:\n",
    "            return('winner')\n",
    "        elif flip == 1:\n",
    "            return('loser')\n",
    "def class_info(sex=str):\n",
    "    ''' Generates list of bilateral neurons from list of neurons, \n",
    "    and gives their class count\n",
    "    output: LR neurons, class count, LR pairs (AL-R), LR classes (A,B...)\n",
    "    sex = 'herm' or 'male' \n",
    "    common = None or 'common'\n",
    "\n",
    "    returns:\n",
    "        neuron: class dic for all neurons\n",
    "        class: neuron count dic\n",
    "        bilateral neuron: class dic for only neurons that are bilateral\n",
    "        bilateral class: neuron count dic\n",
    "        common neurons: class dic\n",
    "    '''\n",
    "    infodf = pd.read_csv(folder_path+'/input_files/celegans_allneurons_info.csv')\n",
    "    \n",
    "    bicladf = infodf[infodf['type']== 'bilateral']\n",
    "    bicladf = bicladf[bicladf['sex'].str.contains(sex)]\n",
    "\n",
    "    df = infodf[infodf['sex'].str.contains(sex)]\n",
    "    neucla = {neu:cla for neu,cla in zip(list(df['neuron']),list(df['class']))}\n",
    "    clacount = dict(Counter(df['class']))\n",
    "    clacount = {k:v for k,v in clacount.items() if not v <= 1}\n",
    " \n",
    "\n",
    "\n",
    "    bicla = {neu:cla for neu,cla in zip(list(bicladf['neuron']),list(bicladf['class']))}\n",
    "    biclacount = dict(Counter(bicladf['class']))\n",
    "    return(neucla,clacount,bicla,biclacount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' calculate Fu for directed connectomes'''\n",
    "\n",
    "\n",
    "\n",
    "def get_directed_asymmetry(filetouse,sourcecol,targetcol,synapsetypecol,dataset=None,common=False,sex='herm' or 'male'):\n",
    "    \n",
    "    data = pd.read_csv(filetouse,sep=',')\n",
    "    common_neurons = pd.read_csv(folder_path+'/input_files/common_neurons_AB01_AB02_SE00.csv',sep = ',',names = ['node'])\n",
    "    common_neurons['node'] = common_neurons['node'].str.strip(\"'\")\n",
    "\n",
    "    LR_class_dic = class_info(sex)[2]\n",
    "    LR_class_count = class_info(sex)[3]\n",
    "\n",
    "    def return_class(tup=tuple or str):\n",
    "        '''takes synapse tuple (neuron,neuron) or neuron as input and \n",
    "        gives class tuple or neuron class as output'''\n",
    "        if isinstance(tup, tuple):\n",
    "            clalis = [LR_class_dic[i] for i in tup if i in LR_class_dic.keys()]\n",
    "            return(tuple(clalis))\n",
    "        if isinstance(tup,str):\n",
    "            if tup in LR_class_dic.keys():\n",
    "                return(LR_class_dic[tup])\n",
    "    \n",
    "    rct = return_class\n",
    "\n",
    "    regex_pattern = 'BWM|um|anal|int|sph|vm|mc|hyp|pm|intestine|intL|GLRDL|GLRDR|GLRL|GLRR|GLRLR|GLRVL|GLRVR|excgl|sh'\n",
    "    if common == True:\n",
    "        data = data.loc[data[sourcecol].isin(common_neurons['node'])]\n",
    "        data = data.loc[data[targetcol].isin(common_neurons['node'])]\n",
    "   \n",
    "\n",
    "    data_chem = data.loc[data[synapsetypecol] == 'chemical']\n",
    "    data_chem = data_chem[~data_chem[sourcecol].str.contains(regex_pattern,regex=True)]\n",
    "    data_chem = data_chem[~data_chem[targetcol].str.contains(regex_pattern,regex=True)]\n",
    "    data_chem.drop_duplicates(inplace=True)\n",
    "    data_chem.reset_index(inplace=True)\n",
    "\n",
    "    chem_net = nx.from_pandas_edgelist(data_chem,source=sourcecol,target=targetcol,create_using=nx.DiGraph)\n",
    "    \n",
    "    chem_net.remove_edges_from(list(nx.selfloop_edges(chem_net)))\n",
    "    chem_deg = [\"%s %s\" % x for x in chem_net.degree()]\n",
    "    dic_chem_deg = dict(s.split(' ') for s in chem_deg)\n",
    "\n",
    "    chem_nodelist = nx.nodes(chem_net)\n",
    "    chem_all_names={}; chem_all_count={}; chem_out_names={};\\\n",
    "         chem_out_count={}; chem_in_names={}; chem_in_count ={}\n",
    "    for node in chem_nodelist:\n",
    "        chem_all_names[node] = list(nx.all_neighbors(chem_net, node)); chem_all_count[node] = len(chem_all_names[node])\n",
    "        chem_out_names[node] = list(chem_net.successors(node)); chem_out_count[node] = len(chem_out_names[node])\n",
    "        chem_in_names[node] = list(chem_net.predecessors(node)); chem_in_count[node] = len(chem_in_names[node])\n",
    "\n",
    "    \n",
    "    def create_contralateral_dict(nodelist, dic):\n",
    "        '''this function will count the unilateral asymmetric\n",
    "        connections between the Left and Right pairs of neurons'''\n",
    "        unique_partners = {}\n",
    "        L_unique_contlat = {}\n",
    "        R_unique_contlat = {}\n",
    "        L_unique_contlat_names = {}\n",
    "        R_unique_contlat_names = {}\n",
    "        notLR= ['PQR','PVR','AVL','RIR','AQR']\n",
    "        for node1, node2 in it.permutations(nodelist,2):\n",
    "            if (node1.endswith(('R')) and node2.endswith(('L'))):\n",
    "                if node1[:-1] == node2[:-1]:\n",
    "                    R_lis = dic[node1]\n",
    "                    L_lis = dic[node2]\n",
    "                    def separate_LR(lis):\n",
    "                        lis_LR = []\n",
    "                        lis_notLR = []\n",
    "                        for i in range(len(lis)):\n",
    "                            if (lis[i] in notLR) or (lis[i].endswith(('L','R')) == False):\n",
    "                                lis_notLR.append(lis[i])\n",
    "                            elif lis[i].endswith(('L','R')):\n",
    "                                lis_LR.append(lis[i])\n",
    "                        return(lis_notLR,lis_LR)\n",
    "\n",
    "                    R_lis_notLR, R_lis_LR = separate_LR(R_lis)\n",
    "                    L_lis_notLR, L_lis_LR = separate_LR(L_lis)\n",
    "\n",
    "                    def count_asymmetry(L_lis, R_lis, L_lis_notLR,R_lis_notLR,lislen1,lislen2):\n",
    "\n",
    "                        count1 = 0\n",
    "                        while count1 < lislen1:\n",
    "                            [(L_lis_notLR.remove(elem),R_lis_notLR.remove(elem) )for elem in L_lis_notLR if elem in R_lis_notLR]\n",
    "\n",
    "                            count1 += 1\n",
    "\n",
    "                        count2 = 0\n",
    "                        while count2 < lislen2:\n",
    "                            for elem in L_lis:\n",
    "                                if elem.endswith(('L')):\n",
    "                                    if (elem[:-1] + 'R') in R_lis:\n",
    "                                        L_lis.remove(elem)\n",
    "                                        R_lis.remove(elem[:-1]+'R')\n",
    "                                elif elem.endswith(('R')):\n",
    "                                    if (elem[:-1]+'L') in R_lis:\n",
    "                                        L_lis.remove(elem)\n",
    "                                        R_lis.remove(elem[:-1]+'L')\n",
    "                            count2 += 1\n",
    "\n",
    "                        L_names = L_lis + list(L_lis_notLR)\n",
    "                        R_names = R_lis + list(R_lis_notLR)\n",
    "                        return(L_names,R_names)\n",
    "                    \n",
    "                    L_contlat_names, R_contlat_names = count_asymmetry(L_lis_LR, R_lis_LR, L_lis_notLR, R_lis_notLR,len(L_lis_notLR+R_lis_notLR),len(L_lis_LR+R_lis_LR))\n",
    "                    \n",
    "                    unique_partners[node1[:-1]+'L'] = L_contlat_names\n",
    "                    unique_partners[node1[:-1]+'R'] = R_contlat_names\n",
    "                    L_unique_contlat_names[node2[:-1]+'L-R'] = L_contlat_names\n",
    "                    R_unique_contlat_names[node1[:-1]+'L-R'] = R_contlat_names\n",
    "                    L_unique_contlat[node2[:-1]+'L-R'] = len(L_contlat_names)\n",
    "                    R_unique_contlat[node1[:-1]+'L-R'] = len(R_contlat_names)\n",
    "\n",
    "        return(L_unique_contlat,R_unique_contlat,L_unique_contlat_names,R_unique_contlat_names,unique_partners)\n",
    "\n",
    "    L_contlat_chem_in, R_contlat_chem_in, L_contlat_chem_in_names, R_contlat_chem_in_names, unique_partners_in = create_contralateral_dict(chem_nodelist, chem_in_names)\n",
    "    L_contlat_chem_out, R_contlat_chem_out, L_contlat_chem_out_names, R_contlat_chem_out_names, unique_partners_out = create_contralateral_dict(chem_nodelist, chem_out_names)\n",
    "\n",
    "\n",
    "    df_unique_partners_in = pd.DataFrame.from_dict(unique_partners_in, orient='index').transpose()\n",
    "    df_unique_partners_in = df_unique_partners_in.melt(var_name='Target', value_name='Source').dropna()\n",
    "    df_unique_partners_in['unique_syn'] = (df_unique_partners_in['Source']+'-'+df_unique_partners_in['Target'])\n",
    "\n",
    "    df_unique_partners_out = pd.DataFrame.from_dict(unique_partners_out, orient='index').transpose()\n",
    "    df_unique_partners_out = df_unique_partners_out.melt(var_name='Source', value_name='Target').dropna()\n",
    "    df_unique_partners_out['unique_syn'] = (df_unique_partners_out['Source']+'-'+df_unique_partners_out['Target'])\n",
    "\n",
    "    unique_partners_df = pd.concat([df_unique_partners_out,df_unique_partners_in], axis=0).sort_values(by='unique_syn')\n",
    "\n",
    "    LR_pairs = list(set(R_contlat_chem_in.keys()).union(set(R_contlat_chem_out.keys())))\n",
    "    chem_ne_dic = {}\n",
    "    for key, val in chem_all_names.items():\n",
    "        chem_ne_dic[key[:-1]+'L-R'] = val\n",
    "        \n",
    "    chem_ne_dic = {key:chem_ne_dic[key] for key in LR_pairs}\n",
    "\n",
    "    asym_conn_dic = {}\n",
    "    asym_conn_dic_in = {}\n",
    "    asym_conn_dic_out = {}\n",
    "    LR_nodelist = list(set(list(L_contlat_chem_in_names.keys())).union(set(list(L_contlat_chem_out_names.keys())),\\\n",
    "        set(list(R_contlat_chem_in_names.keys())),set(list(R_contlat_chem_out_names.keys()))))\n",
    "    for node in LR_nodelist:\n",
    "        asym_conn_dic[node] = L_contlat_chem_in_names[node] + L_contlat_chem_out_names[node] + \\\n",
    "            R_contlat_chem_in_names[node] + R_contlat_chem_out_names[node] \n",
    "        asym_conn_dic_in[node] = L_contlat_chem_in_names[node] + R_contlat_chem_in_names[node]\n",
    "        asym_conn_dic_out[node] = L_contlat_chem_out_names[node] + R_contlat_chem_out_names[node] \n",
    "\n",
    "    LR_nodepairs = list(set(L_contlat_chem_in.keys()).union(set(L_contlat_chem_out.keys()),set(R_contlat_chem_in.keys()),set(R_contlat_chem_out.keys())))\n",
    "    bilat_nodes = []\n",
    "    for nodepair in LR_nodepairs:\n",
    "        nodeL, nodeR = nodepair[:-3] + \"L\" , nodepair[:-3] + \"R\"\n",
    "        bilat_nodes.extend((nodeL, nodeR))\n",
    "\n",
    "    lod = [L_contlat_chem_in,L_contlat_chem_out,R_contlat_chem_in,R_contlat_chem_out] \n",
    "    lod_str = ['L_chem_in_unilat', 'L_chem_out_unilat','R_chem_in_unilat','R_chem_out_unilat']\n",
    "\n",
    "    df_LR_unique_conn = pd.DataFrame(index = sorted(LR_nodepairs))\n",
    "    df_LR_unique_conn['node'] = df_LR_unique_conn.index\n",
    "    for i in range(len(lod)):\n",
    "        df_LR_unique_conn[lod_str[i]] = df_LR_unique_conn['node'].map(lod[i])\n",
    "\n",
    "    df_LR_unique_conn.reset_index(drop=True,inplace=True) \n",
    "    df_LR_unique_conn.fillna(0,inplace=True)\n",
    "    df_LR_unique_conn['chem_total_unique'] = df_LR_unique_conn['L_chem_in_unilat']+df_LR_unique_conn['R_chem_in_unilat']+\\\n",
    "        df_LR_unique_conn['L_chem_out_unilat']+df_LR_unique_conn['R_chem_out_unilat']\n",
    "\n",
    "    df_deg = pd.DataFrame(list(dic_chem_deg.values()),index=list(dic_chem_deg.keys()),columns=['deg'])\n",
    "    df_deg.reset_index(inplace=True)\n",
    "    df_deg.rename({'index':'node'},axis=1,inplace = True)\n",
    "\n",
    "    df_deg['deg'] = df_deg['node'].map(dic_chem_deg).astype(int)\n",
    "    df_deg['chem_deg_in'] = df_deg['node'].map(chem_in_count)\n",
    "    df_deg['chem_deg_out'] = df_deg['node'].map(chem_out_count)\n",
    "\n",
    "    df_deg_L = df_deg.loc[df_deg['node'].str.endswith(('L'))].set_index('node')\n",
    "    df_deg_R = df_deg.loc[df_deg['node'].str.endswith(('R'))].set_index('node')\n",
    "    for df in [df_deg_L,df_deg_R]:\n",
    "        df.index = df.index.str[:-1]\n",
    "        df.reset_index(inplace =True)\n",
    "    \n",
    "    df_asym = df_deg_L.merge(df_deg_R,how='inner',on='node',suffixes=('_L','_R'))\n",
    "    df_asym['node'] = df_asym['node'].astype(str)+'L-R'\n",
    "    df_asym['chem_deg_total_L'] = df_asym['chem_deg_in_L']+df_asym['chem_deg_out_L']\n",
    "    df_asym['chem_deg_total_R'] = df_asym['chem_deg_in_R']+df_asym['chem_deg_out_R']\n",
    "    df_asym['chem_deg_total'] = df_asym['chem_deg_total_L'] +df_asym['chem_deg_total_R']\n",
    "    df_asym['chem_deg_in_total'] = df_asym['chem_deg_in_L'] + df_asym['chem_deg_in_R']\n",
    "    df_asym['chem_deg_out_total'] = df_asym['chem_deg_out_L'] + df_asym['chem_deg_out_R']\n",
    "\n",
    "    df_asym = df_asym.merge(df_LR_unique_conn,how='inner',on='node')\n",
    "    for lettertouse in ['L','R']:\n",
    "        df_asym[lettertouse+'_chem_unilat_total'] = df_asym[lettertouse+'_chem_in_unilat'] + df_asym[lettertouse+'_chem_out_unilat']\n",
    "    \n",
    "    df_asym['chem_unilat_total_in'] = df_asym['R_chem_in_unilat'] + df_asym['L_chem_in_unilat']\n",
    "    df_asym['chem_unilat_total_out'] = df_asym['R_chem_out_unilat'] + df_asym['L_chem_out_unilat']\n",
    "\n",
    "\n",
    "    df_asym['chem_bias'] = df_asym['deg_L']- df_asym['deg_R']\n",
    "    df_asym['chem_uni_bias'] = df_asym['L_chem_unilat_total'] - df_asym['R_chem_unilat_total']\n",
    "    df_asym['chem_deg_all_total'] = df_asym['deg_L'] + df_asym['deg_R']\n",
    "    df_asym['chem_uni_frac_bias'] = df_asym['chem_bias']/(df_asym['L_chem_unilat_total']+df_asym['R_chem_unilat_total'])\n",
    "    df_asym['chem_frac_asym'] = df_asym['chem_total_unique']/ df_asym['chem_deg_all_total']\n",
    "\n",
    "    df_asym['chem_abs_delLR_all'] = (np.sqrt(2.0)/(2.0))*((df_asym['deg_L']-df_asym['deg_R']))\n",
    "    df_asym = df_asym.sort_values(by=['node'])\n",
    "    df_asym = df_asym.set_index('node')\n",
    "    \n",
    "    fu = np.mean(df_asym['chem_frac_asym'])\n",
    "    df_asym = df_asym.add_prefix(dataset)\n",
    "\n",
    "    \n",
    "    return( df_asym, chem_net,data_chem,unique_partners_df,df_unique_partners_in, df_unique_partners_out,fu)\n",
    "AB01_chem_asym, ab01_chem_net,data_chem_ab01,unique_edges_ab01,unique_edges_in_ab01 ,unique_edges_out_ab01,AB01_fu = get_directed_asymmetry(folder_path+\"/raw_data/witvliet_2020_adult_brain_01.csv\",'Source','Target', 'Type', \\\n",
    "    dataset=\"ab01-\",  common=True,sex='herm')\n",
    "AB02_chem_asym, ab02_chem_net,data_chem_ab02,unique_edges_ab02,unique_edges_in_ab02 ,unique_edges_out_ab02,AB02_fu = get_directed_asymmetry(folder_path+\"/raw_data/witvliet_2020_adult_brain_02.csv\",'Source','Target', 'Type', \\\n",
    "    dataset=\"ab02-\",  common=True,sex='herm')\n",
    "SE00_chem_asym, se00_chem_net_whole,data_chem_se00,unique_edges_se00,unique_edges_in_se00 ,unique_edges_out_se00,SE00_fu = get_directed_asymmetry(folder_path+\"/raw_data/celegans_herm_nopharynx_emmonslab.csv\",'Source','Target','Type', \\\n",
    "    dataset=\"se00-\",  common=False,sex='herm')\n",
    "SE01_chem_asym, se01_chem_net,data_chem_se01,unique_edges_se01,unique_edges_in_se01 ,unique_edges_out_se01,SE01_fu = get_directed_asymmetry(folder_path+\"/raw_data/celegans_herm_nopharynx_emmonslab.csv\",'Source','Target', 'Type', \\\n",
    "    dataset=\"se01-\",  common=True,sex='herm')\n",
    "L101_chem_asym, l101_chem_net,data_chem_l101,unique_edges_l101,unique_edges_in_l101 ,unique_edges_out_l101,L101_fu = get_directed_asymmetry(folder_path+\"/raw_data/witvliet_2020_L1_brain_01.csv\",'Source','Target', 'Type', \\\n",
    "    dataset=\"l101-\",  common=True,sex='herm')\n",
    "L201_chem_asym, l201_chem_net,data_chem_l201,unique_edges_l201,unique_edges_in_l201 ,unique_edges_out_l201,L201_fu = get_directed_asymmetry(folder_path+\"/raw_data/witvliet_2020_L2_brain.csv\",'Source','Target', 'Type', \\\n",
    "    dataset=\"l201-\",  common=True,sex='herm')\n",
    "L301_chem_asym, l301_chem_net,data_chem_l301,unique_edges_l301,unique_edges_in_l301 ,unique_edges_out_l301,L301_fu = get_directed_asymmetry(folder_path+\"/raw_data/witvliet_2020_L3_brain.csv\",'Source','Target', 'Type', \\\n",
    "    dataset=\"l301-\",  common=True,sex='herm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' calculate Fu for undirected connectomes'''\n",
    "def get_undirected_asymmetry(filename,dataset,common_neurons_only = False or None):\n",
    "    dataframe = pd.read_csv(filename ,sep=',')\n",
    "    if 'Type' in dataframe.columns:\n",
    "        dataframe = dataframe.loc[(dataframe['Type'] == 'chemical')]\n",
    "        dataframe.drop(columns=['Type','Weight'], inplace=True)\n",
    "    dataframe.drop_duplicates(inplace=True)\n",
    "    \n",
    "    common_neurons = pd.read_csv(folder_path+'/input_files/common_neurons_AB01_AB02_SE00.csv',sep=',',header = None)\n",
    "\n",
    "    LRneurons = pd.read_csv(folder_path+'/input_files/LR_nodepairs_all.csv',sep=',',header=None)\n",
    "    LR_list = []\n",
    "    for node in LRneurons[0]:\n",
    "        LR_list.append(node[:-3]+'L')\n",
    "        LR_list.append(node[:-3]+'R')\n",
    "    regex_pattern = 'BWM|um|anal|int|sph|vm|mc|hyp|pm|intestine|intL|GLRDL|GLRDR|GLRL|GLRR|GLRLR|GLRVL|GLRVR|excgl|sh'\n",
    "    dataframe = dataframe[~dataframe['Source'].str.contains(regex_pattern,regex=True)]\n",
    "    dataframe = dataframe[~dataframe['Target'].str.contains(regex_pattern,regex=True)]\n",
    "    if common_neurons_only:\n",
    "        dataframe = dataframe.loc[dataframe['Source'].isin(common_neurons[0])]\n",
    "        dataframe = dataframe.loc[dataframe['Target'].isin(common_neurons[0])]\n",
    "    \n",
    "    chem_net = nx.from_pandas_edgelist(dataframe,source='Source',target='Target',create_using=nx.Graph)\n",
    "    \n",
    "    chem_net.remove_edges_from(list(nx.selfloop_edges(chem_net)))\n",
    "    chem_deg = [\"%s %s\" % x for x in chem_net.degree()]\n",
    "    dic_chem_deg = dict(s.split(' ') for s in chem_deg)\n",
    "\n",
    "    chem_nodelist = nx.nodes(chem_net)\n",
    "    chem_all_names={}; chem_all_count={}\n",
    "    for node in chem_nodelist:\n",
    "        chem_all_names[node] = list(nx.all_neighbors(chem_net, node))\n",
    "        chem_all_count[node] = len(chem_all_names[node])\n",
    "    def create_contralateral_dict(nodelist, dic):\n",
    "        '''this function will count the unilateral asymmetric\n",
    "        connections between the Left and Right pairs of neurons'''\n",
    "        unique_partners = {}\n",
    "        L_unique_contlat = {}\n",
    "        R_unique_contlat = {}\n",
    "        L_unique_contlat_names = {}\n",
    "        R_unique_contlat_names = {}\n",
    "        for node1, node2 in it.permutations(nodelist,2):\n",
    "            if (node1.endswith(('R')) and node2.endswith(('L'))):\n",
    "                if node1[:-1] == node2[:-1]:\n",
    "                    R_lis = dic[node1]\n",
    "                    L_lis = dic[node2]\n",
    "                    def separate_LR(lis):\n",
    "                        lis_LR = []\n",
    "                        lis_notLR = []\n",
    "                        for i in range(len(lis)):\n",
    "                            if (lis[i] in ['PQR','PVR','AVL','RIR','AQR']) or (lis[i].endswith(('L','R')) == False):\n",
    "                                lis_notLR.append(lis[i])\n",
    "                            elif lis[i].endswith(('L','R')):\n",
    "                                lis_LR.append(lis[i])\n",
    "                        return(lis_notLR,lis_LR)\n",
    "\n",
    "                    R_lis_notLR, R_lis_LR = separate_LR(R_lis)\n",
    "                    L_lis_notLR, L_lis_LR = separate_LR(L_lis)\n",
    "\n",
    "                    def count_asymmetry(L_lis, R_lis, L_lis_notLR,R_lis_notLR,lislen1,lislen2):\n",
    "\n",
    "                        count1 = 0\n",
    "                        while count1 < lislen1:\n",
    "                            [(L_lis_notLR.remove(elem),R_lis_notLR.remove(elem) )for elem in L_lis_notLR if elem in R_lis_notLR]\n",
    "\n",
    "                            count1 += 1\n",
    "\n",
    "                        count2 = 0\n",
    "                        while count2 < lislen2:\n",
    "                            for elem in L_lis:\n",
    "                                if elem.endswith(('L')):\n",
    "                                    if (rc(elem)) in R_lis:\n",
    "                                        L_lis.remove(elem); R_lis.remove(rc(elem))                                        \n",
    "                                elif elem.endswith(('R')):\n",
    "                                    if (rc(elem)) in R_lis:\n",
    "                                        L_lis.remove(elem); R_lis.remove(rc(elem))                                        \n",
    "                            \n",
    "                            count2 += 1\n",
    "\n",
    "                        L_names = L_lis + list(L_lis_notLR)\n",
    "                        R_names = R_lis + list(R_lis_notLR)\n",
    "                        return(L_names,R_names)\n",
    "                    \n",
    "                    L_contlat_names, R_contlat_names = count_asymmetry(L_lis_LR, R_lis_LR, L_lis_notLR, R_lis_notLR,len(L_lis_notLR+R_lis_notLR),len(L_lis_LR+R_lis_LR))\n",
    "                    \n",
    "                    for n in [node1,node2]:\n",
    "                        if n.endswith('L'):\n",
    "                            unique_partners[n] = L_contlat_names\n",
    "                        elif n.endswith('R'):\n",
    "                            unique_partners[n] = R_contlat_names\n",
    "                    unique_partners[node1[:-1]+'L'] = L_contlat_names\n",
    "                    unique_partners[node1[:-1]+'R'] = R_contlat_names\n",
    "                    L_unique_contlat_names[node2[:-1]+'L-R'] = L_contlat_names\n",
    "                    R_unique_contlat_names[node1[:-1]+'L-R'] = R_contlat_names\n",
    "                    L_unique_contlat[node2[:-1]+'L-R'] = len(L_contlat_names)\n",
    "                    R_unique_contlat[node1[:-1]+'L-R'] = len(R_contlat_names)\n",
    "\n",
    "        return(L_unique_contlat,R_unique_contlat,L_unique_contlat_names,R_unique_contlat_names,unique_partners)\n",
    "\n",
    "    L_contlat, R_contlat, L_contlat_names, R_contlat_names, unique_partners = create_contralateral_dict(chem_nodelist, chem_all_names)\n",
    "\n",
    "    LR_pairs = list(set(R_contlat.keys()).union(set(L_contlat.keys())))\n",
    "    chem_ne_dic = {key[:-1]+'L-R': val for key, val in chem_all_names.items()}\n",
    "        \n",
    "    unique_synapses =  [neuron[:-3] + side + '-' + partner for dic, side in zip([L_contlat_names, R_contlat_names], ['L', 'R']) for neuron, partners in dic.items() for partner in partners]\n",
    "\n",
    "    chem_ne_dic = {key:chem_ne_dic[key] for key in LR_pairs}\n",
    "    asym_conn_dic = {}\n",
    "    LR_nodelist = list(set(list(L_contlat_names.keys())).union(set(list(R_contlat_names.keys()))))\n",
    "\n",
    "    for node in LR_nodelist:\n",
    "        asym_conn_dic[node] = L_contlat_names[node] + R_contlat_names[node]\n",
    "\n",
    "    LR_nodepairs = LR_pairs\n",
    "\n",
    "    lod = [L_contlat, R_contlat] \n",
    "    lod_str = ['L_unilat','R_unilat']\n",
    "\n",
    "    df_LR_unique_conn = pd.DataFrame(index = sorted(LR_nodepairs))\n",
    "    df_LR_unique_conn['node'] = df_LR_unique_conn.index\n",
    "    for i in range(len(lod)):\n",
    "        df_LR_unique_conn[lod_str[i]] = df_LR_unique_conn['node'].map(lod[i])\n",
    "    df_LR_unique_conn.reset_index(drop=True,inplace=True) \n",
    "    df_LR_unique_conn.fillna(0,inplace=True)\n",
    "    df_LR_unique_conn['total_unique'] = df_LR_unique_conn['L_unilat']+df_LR_unique_conn['R_unilat']\n",
    "    df_deg = pd.DataFrame(list(dic_chem_deg.values()),index=list(dic_chem_deg.keys()),columns=['deg'])\n",
    "    df_deg.reset_index(inplace=True)\n",
    "    df_deg.rename({'index':'node'},axis=1,inplace = True)\n",
    "    df_deg['deg'] = df_deg['node'].map(dic_chem_deg).astype(int)\n",
    "    df_deg_L = df_deg.loc[df_deg['node'].str.endswith(('L'))].set_index('node')\n",
    "    df_deg_R = df_deg.loc[df_deg['node'].str.endswith(('R'))].set_index('node')\n",
    "    for df in [df_deg_L,df_deg_R]:\n",
    "        df.index = df.index.str[:-1]\n",
    "        df.reset_index(inplace =True)\n",
    "    df_asym = df_deg_L.merge(df_deg_R,how='inner',on='node',suffixes=('_L','_R'))\n",
    "    df_asym['node'] = df_asym['node'].astype(str)+'L-R'\n",
    "    df_asym = df_asym.merge(df_LR_unique_conn,how='inner',on='node')\n",
    "    df_asym['bias'] = df_asym['deg_L']- df_asym['deg_R']\n",
    "    df_asym['uni_bias'] = df_asym['L_unilat'] - df_asym['R_unilat']\n",
    "    df_asym['deg_total'] = df_asym['deg_L'] + df_asym['deg_R']\n",
    "    df_asym['uni_frac_bias'] = df_asym['bias']/(df_asym['L_unilat']+df_asym['R_unilat'])\n",
    "    df_asym['frac_asym'] = round(df_asym['total_unique']/ df_asym['deg_total'],3)\n",
    "    df_asym['delLR'] = (np.sqrt(2.0)/(2.0))*((df_asym['deg_L']-df_asym['deg_R']))\n",
    "    df_asym = df_asym.sort_values(by=['node'])\n",
    "    df_asym = df_asym.set_index('node')\n",
    "    df_asym = df_asym.add_prefix(dataset)\n",
    "    \n",
    "\n",
    "    return(df_asym,chem_net,unique_synapses)\n",
    "\n",
    "ab01_undi_frac_asym, ab01_undi_net, ab01_undi_unqiue_synapses = get_undirected_asymmetry(folder_path+\"/raw_data/witvliet_2020_adult_brain_01.csv\",'ab01-',common_neurons_only=True)\n",
    "ab02_undi_frac_asym, ab02_undi_net, ab02_undi_unqiue_synapses = get_undirected_asymmetry(folder_path+\"/raw_data/witvliet_2020_adult_brain_02.csv\",'ab02-',common_neurons_only=True)\n",
    "se01_undi_frac_asym, se01_undi_net, se01_undi_unqiue_synapses = get_undirected_asymmetry(folder_path+\"/raw_data/celegans_herm_nopharynx_emmonslab.csv\",'se01-',common_neurons_only=True)\n",
    "ab12_undi_frac_asym, ab12_undi_net, ab12_undi_unqiue_synapses = get_undirected_asymmetry(folder_path+\"/raw_data/witvliet_dataset8_vol_contactome.csv\",'ab12-',common_neurons_only=True)\n",
    "se11_undi_frac_asym, se11_undi_net, se11_undi_unqiue_synapses = get_undirected_asymmetry(folder_path+\"/raw_data/cel_n2u_nr_adj_contactome.csv\",'se11-',common_neurons_only=True)\n",
    "se00_undi_frac_asym, se00_undi_net, se00_undi_unqiue_synapses = get_undirected_asymmetry(folder_path+\"/raw_data/celegans_herm_nopharynx_emmonslab.csv\",'se00-',common_neurons_only=False)\n",
    "l101_undi_frac_asym, l101_undi_net, l101_undi_unqiue_synapses = get_undirected_asymmetry(folder_path+\"/raw_data/witvliet_2020_L1_brain_01.csv\",'ab01-',common_neurons_only=True)\n",
    "l201_undi_frac_asym, l201_undi_net, l201_undi_unqiue_synapses = get_undirected_asymmetry(folder_path+\"/raw_data/witvliet_2020_L2_brain.csv\",'ab01-',common_neurons_only=True)\n",
    "l301_undi_frac_asym, l301_undi_net, l301_undi_unqiue_synapses = get_undirected_asymmetry(folder_path+\"/raw_data/witvliet_2020_L3_brain.csv\",'ab01-',common_neurons_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' calculate Fu for undirected connectomes, with only undirected network as input'''\n",
    "def fractional_asymmetry_undirected(network,colname=None):\n",
    "\n",
    "    nodelist = nx.nodes(network)\n",
    "    all_names={node: list(nx.all_neighbors(network,node)) for node in nodelist}\n",
    "    all_count={node: len(all_names[node]) for node in set(all_names)}\n",
    " \n",
    "\n",
    "    def create_contralateral_dict(nodelist, dic):\n",
    "        '''this function will count the unilateral asymmetric\n",
    "        connections between the Left and Right pairs of neurons'''\n",
    "        unique_partners = {}\n",
    "        L_unique_contlat = {}\n",
    "        R_unique_contlat = {}\n",
    "        L_unique_contlat_names = {}\n",
    "        R_unique_contlat_names = {}\n",
    "        for node1, node2 in it.permutations(nodelist,2):\n",
    "            if (node1.endswith(('R')) and node2.endswith(('L'))):\n",
    "                if node1[:-1] == node2[:-1]:\n",
    "                    R_lis = dic[node1]\n",
    "                    L_lis = dic[node2]\n",
    "                    def separate_LR(lis):\n",
    "                        lis_LR = []\n",
    "                        lis_notLR = []\n",
    "                        for i in range(len(lis)):\n",
    "                            if (lis[i] in ['PQR','PVR','AVL','RIR','AQR']) or (lis[i].endswith(('L','R')) == False):\n",
    "                                lis_notLR.append(lis[i])\n",
    "                            elif lis[i].endswith(('L','R')):\n",
    "                                lis_LR.append(lis[i])\n",
    "                        return(lis_notLR,lis_LR)\n",
    "\n",
    "                    R_lis_notLR, R_lis_LR = separate_LR(R_lis)\n",
    "                    L_lis_notLR, L_lis_LR = separate_LR(L_lis)\n",
    "\n",
    "                    def count_asymmetry(L_lis, R_lis, L_lis_notLR,R_lis_notLR,lislen1,lislen2):\n",
    "\n",
    "                        count1 = 0\n",
    "                        while count1 < lislen1:\n",
    "                            [(L_lis_notLR.remove(elem),R_lis_notLR.remove(elem) )for elem in L_lis_notLR if elem in R_lis_notLR]\n",
    "\n",
    "                            count1 += 1\n",
    "\n",
    "                        count2 = 0\n",
    "                        while count2 < lislen2:\n",
    "                            for elem in L_lis:\n",
    "                                if elem.endswith(('L')):\n",
    "                                    if (rc(elem)) in R_lis:\n",
    "                                        L_lis.remove(elem); R_lis.remove(rc(elem))                                        \n",
    "                                elif elem.endswith(('R')):\n",
    "                                    if (rc(elem)) in R_lis:\n",
    "                                        L_lis.remove(elem); R_lis.remove(rc(elem))                                        \n",
    "                            \n",
    "                            count2 += 1\n",
    "\n",
    "                        L_names = L_lis + list(L_lis_notLR)\n",
    "                        R_names = R_lis + list(R_lis_notLR)\n",
    "                        return(L_names,R_names)\n",
    "                    \n",
    "                    L_contlat_names, R_contlat_names = count_asymmetry(L_lis_LR, R_lis_LR, L_lis_notLR, R_lis_notLR,len(L_lis_notLR+R_lis_notLR),len(L_lis_LR+R_lis_LR))\n",
    "                    \n",
    "                    unique_partners[node1[:-1]+'L'] = L_contlat_names\n",
    "                    unique_partners[node1[:-1]+'R'] = R_contlat_names\n",
    "                    L_unique_contlat_names[node2[:-1]+'L-R'] = L_contlat_names\n",
    "                    R_unique_contlat_names[node1[:-1]+'L-R'] = R_contlat_names\n",
    "                    L_unique_contlat[node2[:-1]+'L-R'] = len(L_contlat_names)\n",
    "                    R_unique_contlat[node1[:-1]+'L-R'] = len(R_contlat_names)\n",
    "\n",
    "        return(L_unique_contlat,R_unique_contlat,L_unique_contlat_names,R_unique_contlat_names,unique_partners)\n",
    "\n",
    "    L_contlat, R_contlat, L_contlat_names, R_contlat_names, unique_partners = create_contralateral_dict(nodelist, all_names)\n",
    "    frac_asym = {key: (L_contlat.get(key,[])+R_contlat.get(key,[]))/(all_count[key[:-3]+'L']+all_count[key[:-3]+'R']) for key in set(L_contlat)|set(R_contlat)}\n",
    "    if colname is not None:\n",
    "        frac_asym_df = pd.DataFrame.from_dict(frac_asym,orient='index',columns=[colname])\n",
    "    else:\n",
    "        frac_asym_df = pd.DataFrame.from_dict(frac_asym,orient='index',columns=['frac_asym'])\n",
    "    frac_asym_df = frac_asym_df.sort_index(axis=0)\n",
    "\n",
    "    return(np.mean(list(frac_asym.values())),frac_asym_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Generate class network from neuron network'''\n",
    "def network_neuron_classes(network,directed=None,sex='herm' or 'male' ):\n",
    "\n",
    "    if directed is None:\n",
    "        print('Error: Specify whether the network is directed or not, directed accepts True or False')\n",
    "        return\n",
    "    else:\n",
    "\n",
    "        dataframe = nx.to_pandas_edgelist(network,source='Source',target='Target')\n",
    "        regex_pattern = 'BWM|um|anal|int|sph|vm|mc|hyp|pm|intestine|intL|GLRDL|GLRDR|GLRL|GLRR|GLRLR|GLRVL|GLRVR|excgl|sh'\n",
    "        dataframe = dataframe[~dataframe['Source'].str.contains(regex_pattern,regex=True)]\n",
    "        dataframe = dataframe[~dataframe['Target'].str.contains(regex_pattern,regex=True)]\n",
    "        # if common == True:\n",
    "        #     neuron_class = class_info(sex)[4].values()\n",
    "        #     neuron_class_dict = class_info(sex)[4]\n",
    "        #     dataframe = dataframe.loc[dataframe['Source'].str[:3].isin(neuron_class)]\n",
    "        #     dataframe = dataframe.loc[dataframe['Target'].str[:3].isin(neuron_class)]\n",
    "        #     dataframe = dataframe.replace(neuron_class_dict)\n",
    "        # else:\n",
    "        neuron_class_dict = class_info(sex)[2]\n",
    "        dataframe = dataframe.replace(neuron_class_dict)\n",
    "\n",
    "        if directed == False:\n",
    "            class_net = nx.from_pandas_edgelist(dataframe,source='Source',target='Target',create_using=nx.Graph)\n",
    "        elif directed == True:\n",
    "            class_net = nx.from_pandas_edgelist(dataframe,source='Source',target='Target',create_using=nx.DiGraph)\n",
    "        class_net.remove_edges_from(list(nx.selfloop_edges(class_net)))\n",
    "        return(class_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' convert undirected network into directed network, while preserving its number of nodes and edges'''\n",
    "def undirected_to_directed_random(G_undirected):\n",
    "  \n",
    "    \"\"\"\n",
    "    Converts an undirected graph to a directed graph with randomly assigned directions.\n",
    "\n",
    "    Args:\n",
    "    G_undirected: A networkx undirected graph object.\n",
    "\n",
    "    Returns:\n",
    "    G_directed: A networkx directed graph object with the same number of edges as the\n",
    "    undirected graph but with randomly assigned directions.\n",
    "    \"\"\"\n",
    "    G_directed = nx.DiGraph()\n",
    "    G_directed.add_nodes_from(G_undirected.nodes)\n",
    "\n",
    "    # Add edges with random directions\n",
    "    for edge in G_undirected.edges:\n",
    "        u, v = edge\n",
    "        direction = random.choice([True, False])\n",
    "        if direction:\n",
    "            G_directed.add_edge(u, v)\n",
    "        else:\n",
    "            G_directed.add_edge(v, u)\n",
    "    for edge in G_undirected.edges:\n",
    "        u, v = edge\n",
    "        if u not in G_directed.neighbors(v) and v not in G_directed.neighbors(u):\n",
    "            raise ValueError(\"Edge conversion failed\")\n",
    "\n",
    "    return(G_directed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' calculate Fu for undirected connectomes, with only directed network as input'''\n",
    "def fractional_asymmetry_directed(network,colname=None):\n",
    "    ''' given a toy network of LR nodes, \n",
    "    calculate the fraction of unique synapses'''\n",
    "    LR_neuron_pairs = pd.read_csv(folder_path+'/input_files/celegans_LR_neurons_pairs_combined.csv',sep=',',header=None)\n",
    "    LR_pairs = []\n",
    "    for pair in LR_neuron_pairs[0]:\n",
    "        LR_pairs.append(pair[:-3]+'L');LR_pairs.append(pair[:-3]+'R')\n",
    "    \n",
    "    def is_bilateral(neuron):\n",
    "        if neuron in LR_pairs:\n",
    "            return(True)\n",
    "\n",
    "    net = network\n",
    "    net.remove_edges_from(nx.selfloop_edges((net)))\n",
    "    \n",
    "    all_edges = list(set(net.edges()))\n",
    "    not_bilateral_edge = [edge for edge in all_edges if not (is_bilateral(edge[0]) or is_bilateral(edge[1]))]\n",
    "    asymmetric_synapses = [edge for edge in all_edges \\\n",
    "                           if ((rc(edge[0]),rc(edge[1])) not in all_edges) and (edge != (rc(edge[0]),rc(edge[1]))) and (edge not in not_bilateral_edge)]\n",
    "    symmetric_synapses = [edge for edge in all_edges \\\n",
    "                          if ((rc(edge[0]),rc(edge[1])) in all_edges) and (edge != rc(edge[0]),rc(edge[1])) and (edge not in not_bilateral_edge)]\n",
    "\n",
    "    all_neurons = []\n",
    "    for edg in all_edges:\n",
    "        all_neurons.append(edg[0]);all_neurons.append(edg[1])\n",
    "\n",
    "    all_neurons = list(set(all_neurons))\n",
    "    # all_classes = list(set([neu[:-1] for neu in all_neurons]))\n",
    "    asymmetry = {neu:[] for neu in all_neurons}\n",
    "\n",
    "    for edge in asymmetric_synapses:\n",
    "        #for out-edges\n",
    "        if is_bilateral(edge[0]):\n",
    "            if edge[0] not in asymmetry.keys():\n",
    "                asymmetry.update({edge[0]:[]})\n",
    "                asymmetry[edge[0]].append(edge[1])\n",
    "            elif edge[0] in asymmetry.keys():\n",
    "                asymmetry[edge[0]].append(edge[1])\n",
    " \n",
    "        if is_bilateral(edge[1]):\n",
    "            if edge[1] not in asymmetry.keys():\n",
    "                asymmetry.update({edge[1]:[]})\n",
    "                asymmetry[edge[1]].append(edge[0])\n",
    "            elif edge[1] in asymmetry.keys():\n",
    "                asymmetry[edge[1]].append(edge[0])\n",
    "    asymmetryx = {k: len(asymmetry[k])/nx.degree(net,k) for k in asymmetry.keys()}\n",
    "\n",
    "    asymmetry = {k1[:-1]+'L-R':(len(asymmetry[k1])+len(asymmetry[k2]))/(nx.degree(net,k1)+nx.degree(net,k2)) for k1,k2 in it.combinations(asymmetry.keys(),2) if k1[:-1]==k2[:-1] and k1!=k2 and is_bilateral(k1)}\n",
    "\n",
    "    \n",
    "    if colname is not None:\n",
    "        asymmetry_df = pd.DataFrame.from_dict(asymmetry, orient='index',columns=[colname])\n",
    "    else:\n",
    "        asymmetry_df = pd.DataFrame.from_dict(asymmetry, orient='index')\n",
    "    fraction_unique_synapses = asymmetry_df[0].mean()\n",
    "    asymmetry_df = asymmetry_df.sort_index(axis=0)\n",
    "\n",
    "\n",
    "    return(fraction_unique_synapses,asymmetry_df,asymmetryx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' calculate average shortest path length of a Directed network'''\n",
    "def get_average_shortest_directed_path_length(network):\n",
    "    '''' directed shortest path will be calculated only for\n",
    "    the nodes for which such path exists'''\n",
    "    avg_sp = []\n",
    "    for n1,n2 in it.permutations(network.nodes(),2):\n",
    "        if nx.has_path(network,n1,n2):\n",
    "            avg_sp.append(nx.shortest_path_length(network,n1,n2))\n",
    "    return(np.mean(avg_sp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' DFS algorithm to find all nodes that can be reached with desired path length from a starting node'''\n",
    "def all_nodes_reachable_dfs(graph, start, length):\n",
    "    def dfs(node, path_length):\n",
    "        if path_length == length:\n",
    "            reachable_nodes.append(node)\n",
    "            return\n",
    "        visited.add(node)\n",
    "        for neighbor in graph[node]:\n",
    "            if neighbor not in visited:\n",
    "                dfs(neighbor, path_length + 1)\n",
    "        visited.remove(node)\n",
    "\n",
    "    reachable_nodes = []\n",
    "    visited = set()\n",
    "    for end in graph:\n",
    "        if end == start:\n",
    "            continue\n",
    "        dfs(start, 0)\n",
    "    return (list(set(reachable_nodes)))\n",
    "\n",
    "\n",
    "''' Calculae Redundancy and Reachability for a given network'''\n",
    "def redundancy_diversity(network,desired_path_length,directed,sex='herm' or 'male'):\n",
    "\n",
    "    LR_class_dic = class_info(sex)[2]\n",
    "    LR_class_count = class_info(sex)[3]\n",
    "\n",
    "    def return_class_tuple(tup=tuple or str):\n",
    "        '''takes edge or neuron as input and \n",
    "        gives class tuple or neuron class as outpu'''\n",
    "        if isinstance(tup, tuple):\n",
    "            clalis = [LR_class_dic[i] for i in tup if i in LR_class_dic.keys()]\n",
    "            return(tuple(clalis))\n",
    "        if isinstance(tup,str):\n",
    "            if tup in LR_class_dic.keys():\n",
    "                return(LR_class_dic[tup])\n",
    "    \n",
    "    rct = return_class_tuple\n",
    "\n",
    "    def neurons_in_class(lis):\n",
    "        neus = []\n",
    "        for neu in lis:\n",
    "            if neu in LR_class_count.keys():\n",
    "                neus.append(LR_class_count[neu])\n",
    "        return(math.prod(neus))\n",
    "    \n",
    "    # generate list of nodes which are bilateral or belong to class of bilateral neurons\n",
    "    LRneu = [neu for neu in network.nodes() if neu in LR_class_dic.keys()]\n",
    "\n",
    "    # generate list of classes in the network\n",
    "    LR_classes = list(set(rct(tuple(LRneu))))\n",
    "\n",
    "    # generate dictionary of class pairs for which to find class paths\n",
    "    if not directed:\n",
    "        neuron_path_dict = {(cla1,cla2): []  for cla1,cla2 in it.combinations(LR_classes,2) if cla1 != cla2}\n",
    "    elif directed:\n",
    "        neuron_path_dict = {(cla1,cla2): []  for cla1,cla2 in it.permutations(LR_classes,2) if cla1 != cla2}\n",
    "\n",
    "    # find redundant paths between the classes\n",
    "    for na,nb in it.permutations(LRneu,2):\n",
    "        if na in network.nodes() and nb in network.nodes():\n",
    "            if (rct(na) != rct(nb)) and ((rct(na), rct(nb)) in neuron_path_dict.keys()):\n",
    "                if nx.has_path(network,na,nb):# check if any path between the two nodes\n",
    "                    # find all simple paths between the nodes and select the paths of desired path-length \n",
    "                    paths = [tuple(path) for path in nx.all_simple_paths(network,na,nb,desired_path_length) if len(path) == (desired_path_length+1)]\n",
    "                    if len(paths)>0:\n",
    "                        # add the paths to class pair key\n",
    "                        neuron_path_dict[(rct(na),rct(nb))].append(paths)\n",
    "\n",
    "    neuron_path_dict = {key:[item for sublist in values for item in sublist] for key,values in neuron_path_dict.items()}\n",
    "\n",
    "    # count number of paths for each class pair and create dictionary\n",
    "    red_class_paths = []\n",
    "    for _,neuron_paths in neuron_path_dict.items():\n",
    "        class_paths = list(tuple(rct(s) for s in tpl) for tpl in neuron_paths)\n",
    "        red_class_paths.append(dict(Counter(class_paths)))\n",
    "\n",
    "    # normalize paths by total realizable paths for each class pair\n",
    "    red_class_paths_dic = {}\n",
    "    for d in red_class_paths:\n",
    "        for key,val in d.items():\n",
    "            if len(list(set(key))) == len(key):\n",
    "                red_class_paths_dic[key] = val/neurons_in_class(key)\n",
    "\n",
    "    # print(sum( red_class_paths_dic.values()),(len(red_class_paths_dic.keys())))\n",
    "    # convert network into class network\n",
    "    diversity={cla:[] for cla in LR_classes}\n",
    "    \n",
    "    for node in network.nodes():\n",
    "        if rct(node) in LR_classes:\n",
    "            # DFS algorithm used to find all classes reached by each class with desired path length\n",
    "            diversity[rct(node)].extend([rct(reached) for reached in all_nodes_reachable_dfs(network,node,desired_path_length) if rct(reached) in LR_classes and (rct(reached) != rct(node))])\n",
    "    \n",
    "    diversity = {k:sorted(list(set(v))) for k,v in diversity.items()}       \n",
    "    # print(diversity)\n",
    "    diversity ={key:len((set((val)))) for key,val in diversity.items() if val is not None}\n",
    "\n",
    "    redundancy = sum( red_class_paths_dic.values())/(len(red_class_paths_dic.keys()))\n",
    "    reachability = sum(diversity.values())/(len(diversity.keys())*(len(diversity.keys())-1))\n",
    "\n",
    "    return(round(redundancy,3),round(reachability,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Calculate Rp1, Su1, FpR1, FuS1'''\n",
    "def calculate_fuR1fpS1(network, sex='herm' or 'male', directed=bool):\n",
    "    '''which network takes following arguments:\n",
    "        hermaphrodite, male, commonSE01AB01AB02, pharynx\n",
    "        \n",
    "        returns:fuR1, fpR1, Rp1, fpS1, Sp1, Su1, FuS1'''\n",
    "    \n",
    "    neucla = class_info(sex)[2]\n",
    "    class_counts = class_info(sex)[3]\n",
    "    class_pairs = {(k1,k2):[] for k1,k2 in it.permutations(list(class_counts.keys()),2) if k1!=k2}\n",
    "\n",
    "    neu_in_class = {k:[] for k in list(set(neucla.values()))}\n",
    "    for k,v in neucla.items():\n",
    "        neu_in_class[v].append(k)\n",
    "\n",
    "    def neurons_in_class(lis):\n",
    "        neus = []\n",
    "        for neu in lis:\n",
    "            if neu in class_counts.keys():\n",
    "                neus.append(class_counts[neu])\n",
    "\n",
    "        return(math.prod(neus))\n",
    "\n",
    "    def return_class_tuple(tup=tuple or str):\n",
    "        '''takes edge or neuron as input and \n",
    "        gives class tuple or neuron class as output'''\n",
    "        if isinstance(tup, tuple):\n",
    "            clalis = [neucla[i] for i in tup if i in neucla.keys()]\n",
    "            return(tuple(clalis))\n",
    "        if isinstance(tup,str):\n",
    "            if tup in neucla.keys():\n",
    "                return(neucla[tup])\n",
    "\n",
    "    rct = return_class_tuple\n",
    "\n",
    "    # find all neuron paths for each class pair\n",
    "    for k in class_pairs.keys():\n",
    "        for n1 in neu_in_class[k[0]]:\n",
    "            for n2 in neu_in_class[k[1]]:\n",
    "                if network.has_edge(n1,n2):\n",
    "                    class_pairs[k].append((n1,n2))\n",
    "    class_pairs = {k:v for k,v in class_pairs.items() if len(v) !=0}\n",
    "\n",
    "    # for each class pair, find maximum number of neuron paths\n",
    "    realizable_paths = {k:neurons_in_class(list(k)) for k in class_pairs.keys()}\n",
    "\n",
    "    paired_synapse_per_class = {k:[] for k in class_pairs.keys()}\n",
    "    unpaired_synpse_per_class = {k:[] for k in class_pairs.keys()}\n",
    "    # find paired and unpaired synapses for each class pair\n",
    "    for k,lis in class_pairs.items():\n",
    "        for edg in lis:\n",
    "            rcedg = (rc(edg[0]),rc(edg[1]))\n",
    "            if rcedg not in lis:\n",
    "                unpaired_synpse_per_class[k].append(edg)\n",
    "            elif rcedg in lis:\n",
    "                paired_synapse_per_class[k].extend([edg,rcedg])\n",
    "\n",
    "    unpaired_synapse_per_class = {k:v for k,v in unpaired_synpse_per_class.items()}\n",
    "    paired_synapse_per_class = {k:list(set(v)) for k,v in paired_synapse_per_class.items()}\n",
    "\n",
    "    avg_unp_syn = {k:len(v)/len(class_pairs[k]) for k,v in unpaired_synapse_per_class.items()}\n",
    "    avg_pai_syn_prime = {k:len(v)/realizable_paths[k] for k,v in paired_synapse_per_class.items()}\n",
    "    avg_unp_syn_prime = {k:len(v)/realizable_paths[k] for k,v in unpaired_synapse_per_class.items()}\n",
    "\n",
    "    r1,s1 = redundancy_diversity(network,1,directed=directed,sex=sex)\n",
    "\n",
    "    fuR1 = round(sum(avg_unp_syn_prime.values())/len(avg_unp_syn_prime.keys()),3)/r1\n",
    "    fpR1 = round(sum(avg_pai_syn_prime.values())/len(avg_pai_syn_prime.keys()),3)/r1\n",
    "\n",
    "    Rp1=sum(avg_pai_syn_prime.values())/len(avg_pai_syn_prime.keys())\n",
    "\n",
    "\n",
    "\n",
    "    node_class = list(set(rct(tuple(network.nodes()))))\n",
    "\n",
    "\n",
    "    cla_nodes = {cla:[] for cla in node_class}\n",
    "    # generate a dictionary for nodes:neighbbors, for neighbors which belong to bilateral class\n",
    "    node_nei = {n:[i for i in nx.all_neighbors(network,n) if rct(i) is not None] for n in network.nodes() if rct(n) is not None}\n",
    "\n",
    "    # generate a list of bilateral classes\n",
    "    LRnodecla = list(set([neu[:-1] for neu in node_nei.keys()]))\n",
    "\n",
    "    cla_nei = {cla:[] for cla in node_class}\n",
    "    for node in network.nodes():\n",
    "        if rct(node) is not None: # check if node belongs to bilateral neurons\n",
    "            # for each node find all its neighbors which belong to bilateral neurons\n",
    "            cla_nei[rct(node)].extend([rct(n) for n in nx.all_neighbors(network,node) if rct(n) is not None])\n",
    "                    \n",
    "    cla_nei = {k:set(v) for k,v in cla_nei.items()}\n",
    "\n",
    "    # find all the bilateral neighbors of nodes which can be reached by paired synapses\n",
    "    cla_paired = {k:[] for k in cla_nodes.keys()}\n",
    "    cla_unpaired = {k:[] for k in cla_nodes.keys()}\n",
    "    for cla in LRnodecla:\n",
    "        if cla+'L' in node_nei.keys() and cla+'R' in node_nei.keys():\n",
    "            nl = node_nei[cla+'L'];nr = node_nei[cla+'R']\n",
    "            for neu in nl:\n",
    "                if rct(neu) != rct(cla+'L'):\n",
    "                    if rc(neu) in nr:\n",
    "                        cla_paired[rct(cla+'L')].append(rct(neu))\n",
    "                    elif rc(neu) not in nr:\n",
    "                        cla_unpaired[rct(cla+'L')].append(rct(neu))\n",
    "            for neu in nr:\n",
    "                if rct(neu) != rct(cla+'L'):\n",
    "                    if rc(neu) not in nl:\n",
    "                        cla_unpaired[rct(cla+'L')].append(rct(neu))\n",
    "                    elif rc(neu) not in nl:\n",
    "                        cla_unpaired[rct(cla+'L')].append(rct(neu))\n",
    "            \n",
    "    cla_paired = {k:sorted(list(set(v))) for k,v in cla_paired.items() if v is not None}\n",
    "    cla_unpaired = {k:list(set(v)) for k,v in cla_unpaired.items()}\n",
    "    cla_only_paired = {k:len(list(set(cla_paired[k]).difference(set(cla_unpaired[k])))) for k in cla_paired.keys()}\n",
    "\n",
    "\n",
    "    only_pai_syn_cla = {k:cla_only_paired[k]/len(cla_nei[k]) for k in cla_only_paired.keys() if len(cla_nei[k]) != 0} #empty dictionary to record the classes reached by paired synapses by each class\n",
    "    avg_pai_syn_cla = {k:len(v) for k,v in cla_paired.items()}\n",
    "    avg_unp_syn_cla = {k:len(v) for k,v in cla_unpaired.items()}\n",
    "    Su1 = sum(avg_unp_syn_cla.values())/((len(avg_unp_syn_cla.keys()))*(len(avg_unp_syn_cla.keys())-1))\n",
    "    Sp1 = sum(avg_pai_syn_cla.values())/((len(avg_pai_syn_cla.keys()))*(len(avg_pai_syn_cla.keys())-1))\n",
    "\n",
    "\n",
    "    fpS1 = sum(only_pai_syn_cla.values())/len(only_pai_syn_cla.keys())\n",
    "\n",
    "    fuS1 = Su1/s1\n",
    "    # print(round(fuR1prime,3),round(fpR1,3),round(fpS1,3),round(Sp1,3))\n",
    "    return(round(fuR1,3),round(fpR1,3),round(Rp1,3),round(fpS1,3),round(Sp1,3),round(Su1,3),round(fuS1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' drive network towards complete asymmetry and symmetry '''\n",
    "\n",
    "def symmetrize_asymmetrize_network(network_to_asym,network_to_sym,seed,network_size=None,keys_to_use=None,sex='herm' or 'male'):\n",
    "\n",
    "    print('starting fu', fractional_asymmetry_undirected(network_to_asym)[0])\n",
    "    random.seed(seed)\n",
    "\n",
    "    edges_add = list(set((u,v )for u,v in it.permutations(network_to_asym.nodes(),2) if not network_to_asym.has_edge(u,v)))\n",
    "    \n",
    "    if keys_to_use == None:\n",
    "        keys = [str(n/10) for n in range(11)]\n",
    "\n",
    "    else:\n",
    "        keys = keys_to_use\n",
    "    dic ={key:None for key in keys}\n",
    "\n",
    "    def add_to_dic(dic,net,asymmetry,network_size=network_size):\n",
    "        fu = asymmetry\n",
    "        cc = nx.average_clustering(net)\n",
    "        sp = nx.average_shortest_path_length(net)\n",
    "        r1,s1 = redundancy_diversity(net,1,False,sex=sex)\n",
    "        r2,s2 = redundancy_diversity(net,2,False,sex=sex)\n",
    "        r3,s3 = redundancy_diversity(net,3,False,sex=sex)\n",
    "        net_to_save = nx.to_dict_of_lists(net)\n",
    "        if network_size == 'small':\n",
    "            dic[str(round(asymmetry,ndigits=1))] = {'fu': fu, 'cc': cc, 'sp': sp, 'r1': r1, 'r2': r2, 'r3': r3, 's1': s1, 's2': s2, 's3': s3, 'net': net_to_save, 'seed': seed}\n",
    "        else:\n",
    "            dic[str(round(asymmetry,2))] = {'fu': fu, 'cc': cc, 'sp': sp, 'r1': r1, 'r2': r2, 'r3': r3, 's1': s1, 's2': s2, 's3': s3, 'net': net_to_save, 'seed': seed}\n",
    "        return(dic)\n",
    "    \n",
    "    keys_to_check = [float(v) for v in keys]\n",
    "    print('asymmetrization started')\n",
    " \n",
    "    itr=0\n",
    "    asymmetry = 0\n",
    "    # time.sleep(1)\n",
    "    timeout = time.time() + 30\n",
    "    while asymmetry < round(max(keys_to_check),ndigits=1) :\n",
    "        # print(asymmetry)\n",
    "        edgelist = set((e[0],e[1]) for e in network_to_asym.edges())\n",
    "        edges_to_add = edges_add\n",
    "        edges_to_remove = edgelist\n",
    "        \n",
    "        edge_to_remove = random.choice(list(edges_to_remove))\n",
    "        edge_to_add = random.choice(list(edges_to_add))\n",
    "        # print(edge_to_add,edge_to_remove)\n",
    "        if not network_to_asym.has_edge(edge_to_add[0],edge_to_add[1]):\n",
    "            if len(list(network_to_asym.neighbors(edge_to_remove[0]))) >1 and \\\n",
    "                    len(list(network_to_asym.neighbors(edge_to_remove[1]))) >1:\n",
    "                    network_to_asym.add_edge(edge_to_add[0],edge_to_add[1])\n",
    "                    network_to_asym.remove_edge(edge_to_remove[0],edge_to_remove[1])\n",
    "                    if (nx.degree(network_to_asym,edge_to_remove[0])!=0 and nx.degree(network_to_asym,edge_to_remove[1])!=0):\n",
    "                        asym,asym_df = fractional_asymmetry_undirected(network_to_asym)\n",
    "                        if (round(asym,4) > round( asymmetry,4)) and (nx.is_connected(network_to_asym)):#this if-else loop acts as a feedback\n",
    "                            asymmetry = round(asym,4)\n",
    "                            edges_add.remove(edge_to_add)\n",
    "                            edges_add.append(edge_to_remove)\n",
    "                            asymmetry,asym_df = fractional_asymmetry_undirected(network_to_asym)\n",
    "                            net = network_to_asym.copy()\n",
    "\n",
    "                            if str(asymmetry) == '1.0':\n",
    "                                if '1.0' in dic.keys():\n",
    "                                    dic = add_to_dic(dic,net,asymmetry,network_size)  \n",
    "                            elif (str(round(asymmetry,2)) in dic.keys()) and (dic[str(round(asymmetry,2))]==None) and (str(round(asymmetry,2))!='1.0'):\n",
    "                                dic = add_to_dic(dic,net,asymmetry,network_size)\n",
    "                            elif network_size == 'small':#haven't worked on 0/1 conditions\n",
    "                                if (str(round(asymmetry,ndigits=1)) in dic.keys()) and (dic[str(round(asymmetry,ndigits=1))]==None) and (str(round(asymmetry,ndigits=1))!='1.0'):\n",
    "                                    dic = add_to_dic(dic,net,asymmetry,network_size)\n",
    "                                    # print(dic.keys())\n",
    "                            itr+=1\n",
    "                            # print(asymmetry)\n",
    "                        else:\n",
    "                            network_to_asym.remove_edge(*edge_to_add)\n",
    "                            network_to_asym.add_edge(*edge_to_remove)\n",
    "        elif (network_size == 'small') and (time.time()>timeout):\n",
    "            print('Timeout')\n",
    "            break\n",
    "    print('asymmetrization done')\n",
    "\n",
    "    print('symmetrization started')\n",
    "    timeout = time.time() + 30\n",
    "    sym_itr=0\n",
    "    symmetry,df = fractional_asymmetry_undirected(network_to_sym)\n",
    "    sym_edges_add = list(set((u,v )for u,v in it.permutations(network_to_sym.nodes(),2) if not network_to_sym.has_edge(u,v)))\n",
    "    symmetry = symmetry\n",
    "    while symmetry> round(min(keys_to_check),ndigits=1):\n",
    "        sym_edgelist = set((e[0],e[1]) for e in network_to_sym.edges())\n",
    "        sym_edges_to_add = sym_edges_add\n",
    "        sym_edges_to_remove = sym_edgelist\n",
    "        sym_edge_to_remove = random.choice(list(sym_edges_to_remove))\n",
    "        sym_edge_to_add = random.choice(list(sym_edges_to_add))\n",
    "        if not network_to_sym.has_edge(sym_edge_to_add[0],sym_edge_to_add[1]):\n",
    "            if len(list(network_to_sym.neighbors(sym_edge_to_remove[0]))) >1 and \\\n",
    "                    len(list(network_to_sym.neighbors(sym_edge_to_remove[1]))) >1:\n",
    "                    network_to_sym.add_edge(sym_edge_to_add[0],sym_edge_to_add[1])\n",
    "                    network_to_sym.remove_edge(sym_edge_to_remove[0],sym_edge_to_remove[1])\n",
    "                    if (nx.degree(network_to_sym,sym_edge_to_remove[0])!=0) and (nx.degree(network_to_sym,sym_edge_to_remove[1])!=0):\n",
    "                        asym,asym_df = fractional_asymmetry_undirected(network_to_sym)\n",
    "                        # print(asymmetry)\n",
    "                        if (round(asym,4) < round( symmetry,4)) and (nx.is_connected(network_to_sym)):#this if-else loop acts as a feedback\n",
    "                            symmetry = round(asym,4)\n",
    "                            # print(symmetry)\n",
    "                            sym_edges_add.remove(sym_edge_to_add)\n",
    "                            sym_edges_add.append(sym_edge_to_remove)\n",
    "                            symmetry,asym_df = fractional_asymmetry_undirected(network_to_sym)\n",
    "                            net_sym = network_to_sym.copy()\n",
    "                            if str(symmetry) == '0.0':\n",
    "                                if '0.0' in dic.keys():\n",
    "                                    dic = add_to_dic(dic,net_sym,symmetry,network_size)  \n",
    "                            elif (str(round(symmetry,2)) in dic.keys()) and (dic[str(round(symmetry,2))]==None)and (str(round(symmetry,2))!='0.0'):\n",
    "                                dic = add_to_dic(dic,net_sym,symmetry,network_size)\n",
    "                                # print(dic)\n",
    "                            elif network_size == 'small':\n",
    "                                if (str(round(symmetry,ndigits=1)) in dic.keys()) and (dic[str(round(symmetry,ndigits=1))]==None) and (str(round(symmetry,ndigits=1))!='0.0'):\n",
    "                                    dic = add_to_dic(dic,net_sym,symmetry,network_size)\n",
    "                            sym_itr+=1\n",
    "                        else:\n",
    "                            network_to_sym.remove_edge(sym_edge_to_add[0],sym_edge_to_add[1])\n",
    "                            network_to_sym.add_edge(*sym_edge_to_remove)\n",
    "    print('symmetrization done')\n",
    "\n",
    "\n",
    "    return(dic) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the codes below generate data for the indicated figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SE01</th>\n",
       "      <th>AB01</th>\n",
       "      <th>AB02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADAL</th>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAR</th>\n",
       "      <td>34</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADEL</th>\n",
       "      <td>41</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADER</th>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADFL</th>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URXR</th>\n",
       "      <td>48</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYDL</th>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYDR</th>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYVL</th>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYVR</th>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SE01  AB01  AB02\n",
       "ADAL     34    32    28\n",
       "ADAR     34    29    22\n",
       "ADEL     41    32    32\n",
       "ADER     36    38    35\n",
       "ADFL     30    25    21\n",
       "...     ...   ...   ...\n",
       "URXR     48    25    21\n",
       "URYDL    19    18    19\n",
       "URYDR    19    13    16\n",
       "URYVL    23    17    20\n",
       "URYVR    25    14    22\n",
       "\n",
       "[180 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' degree of each neuron, Fig 1A, 1B'''\n",
    "degdic={}\n",
    "se01deg={};ab01deg={};ab02deg={}\n",
    "for net,name,dic in zip([se01_chem_net,ab01_chem_net,ab02_chem_net],['SE01','AB01','AB02'],[se01deg,ab01deg,ab02deg]):\n",
    "    for tup in nx.degree(net):\n",
    "        dic[tup[0]] = tup[1]\n",
    "    degdic[name] = dic\n",
    "\n",
    "dfdeg = pd.DataFrame.from_dict(degdic,orient='index')\n",
    "dfdeg = dfdeg.T\n",
    "dfdeg = dfdeg.sort_index(axis=0)\n",
    "dfdeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">SE01</th>\n",
       "      <th colspan=\"2\" halign=\"left\">AB01</th>\n",
       "      <th colspan=\"2\" halign=\"left\">AB02</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_1</th>\n",
       "      <th>Left</th>\n",
       "      <th>Right</th>\n",
       "      <th>Left</th>\n",
       "      <th>Right</th>\n",
       "      <th>Left</th>\n",
       "      <th>Right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADA</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADE</th>\n",
       "      <td>41</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADF</th>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADL</th>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFD</th>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URAV</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URB</th>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URX</th>\n",
       "      <td>41</td>\n",
       "      <td>48</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYD</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYV</th>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SE01       AB01       AB02      \n",
       "level_1 Left Right Left Right Left Right\n",
       "ADA       34    34   32    29   28    22\n",
       "ADE       41    36   32    38   32    35\n",
       "ADF       30    37   25    18   21    17\n",
       "ADL       33    41   27    16   31    22\n",
       "AFD       15    13   10     8   12    10\n",
       "...      ...   ...  ...   ...  ...   ...\n",
       "URAV      20    20   11    11    9     8\n",
       "URB       19    33   24    20   25    15\n",
       "URX       41    48   33    25   21    21\n",
       "URYD      19    19   18    13   19    16\n",
       "URYV      23    25   17    14   20    22\n",
       "\n",
       "[83 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' deg of Left and Right neurons in each class, Fig 1C'''\n",
    "notlr = ['PQR','PVR','AVL','RIR','AQR']\n",
    "LRdegdic = {}\n",
    "se01deg={};ab01deg={};ab02deg={}\n",
    "for net,name,dic in zip([se01_chem_net,ab01_chem_net,ab02_chem_net],['SE01','AB01','AB02'],[se01deg,ab01deg,ab02deg]):\n",
    "    for tup in nx.degree(net):\n",
    "        if tup[0] not in notlr:\n",
    "            if tup[0].endswith('L'):\n",
    "                dic[(tup[0][:-1],'Left')] = tup[1]\n",
    "            elif tup[0].endswith('R'):\n",
    "                dic[(tup[0][:-1],'Right')] = tup[1]\n",
    "    LRdegdic[name] = dic\n",
    "LRdfdeg = pd.DataFrame.from_dict(LRdegdic,orient='index')\n",
    "LRdfdeg = LRdfdeg.T\n",
    "LRdfdeg = LRdfdeg.sort_index(axis=0)\n",
    "LRdfdeg.reset_index(level=1,drop=False,inplace=True)\n",
    "LRdfdeg = LRdfdeg.pivot(columns=['level_1'])\n",
    "LRdfdeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SE01</th>\n",
       "      <th>AB01</th>\n",
       "      <th>AB02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADA</th>\n",
       "      <td>0.000</td>\n",
       "      <td>2.121</td>\n",
       "      <td>4.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADE</th>\n",
       "      <td>3.536</td>\n",
       "      <td>-4.243</td>\n",
       "      <td>-2.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADF</th>\n",
       "      <td>-4.950</td>\n",
       "      <td>4.950</td>\n",
       "      <td>2.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADL</th>\n",
       "      <td>-5.657</td>\n",
       "      <td>7.778</td>\n",
       "      <td>6.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFD</th>\n",
       "      <td>1.414</td>\n",
       "      <td>1.414</td>\n",
       "      <td>1.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URAV</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URB</th>\n",
       "      <td>-9.899</td>\n",
       "      <td>2.828</td>\n",
       "      <td>7.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URX</th>\n",
       "      <td>-4.950</td>\n",
       "      <td>5.657</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYD</th>\n",
       "      <td>0.000</td>\n",
       "      <td>3.536</td>\n",
       "      <td>2.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYV</th>\n",
       "      <td>-1.414</td>\n",
       "      <td>2.121</td>\n",
       "      <td>-1.414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SE01   AB01   AB02\n",
       "ADA   0.000  2.121  4.243\n",
       "ADE   3.536 -4.243 -2.121\n",
       "ADF  -4.950  4.950  2.828\n",
       "ADL  -5.657  7.778  6.364\n",
       "AFD   1.414  1.414  1.414\n",
       "...     ...    ...    ...\n",
       "URAV  0.000  0.000  0.707\n",
       "URB  -9.899  2.828  7.071\n",
       "URX  -4.950  5.657  0.000\n",
       "URYD  0.000  3.536  2.121\n",
       "URYV -1.414  2.121 -1.414\n",
       "\n",
       "[83 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''del dk, eucledian distance of dk from symmetry line, Fig S1A, S1B '''\n",
    "\n",
    "deldk = pd.DataFrame()\n",
    "cons = np.sqrt(2)/2\n",
    "\n",
    "for name in ['SE01','AB01','AB02']:\n",
    "    deldk[name] = round((LRdfdeg.loc[:,(name,'Left')] - LRdfdeg.loc[:,(name,'Right')])*cons,3)\n",
    "\n",
    "deldk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(SE01, dk)</th>\n",
       "      <th>(SE01, deldk)</th>\n",
       "      <th>(AB01, dk)</th>\n",
       "      <th>(AB01, deldk)</th>\n",
       "      <th>(AB02, dk)</th>\n",
       "      <th>(AB02, deldk)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADA</th>\n",
       "      <td>68</td>\n",
       "      <td>0.000</td>\n",
       "      <td>61</td>\n",
       "      <td>2.121</td>\n",
       "      <td>50</td>\n",
       "      <td>4.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADE</th>\n",
       "      <td>77</td>\n",
       "      <td>3.536</td>\n",
       "      <td>70</td>\n",
       "      <td>-4.243</td>\n",
       "      <td>67</td>\n",
       "      <td>-2.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADF</th>\n",
       "      <td>67</td>\n",
       "      <td>-4.950</td>\n",
       "      <td>43</td>\n",
       "      <td>4.950</td>\n",
       "      <td>38</td>\n",
       "      <td>2.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADL</th>\n",
       "      <td>74</td>\n",
       "      <td>-5.657</td>\n",
       "      <td>43</td>\n",
       "      <td>7.778</td>\n",
       "      <td>53</td>\n",
       "      <td>6.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFD</th>\n",
       "      <td>28</td>\n",
       "      <td>1.414</td>\n",
       "      <td>18</td>\n",
       "      <td>1.414</td>\n",
       "      <td>22</td>\n",
       "      <td>1.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URAV</th>\n",
       "      <td>40</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000</td>\n",
       "      <td>17</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URB</th>\n",
       "      <td>52</td>\n",
       "      <td>-9.899</td>\n",
       "      <td>44</td>\n",
       "      <td>2.828</td>\n",
       "      <td>40</td>\n",
       "      <td>7.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URX</th>\n",
       "      <td>89</td>\n",
       "      <td>-4.950</td>\n",
       "      <td>58</td>\n",
       "      <td>5.657</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYD</th>\n",
       "      <td>38</td>\n",
       "      <td>0.000</td>\n",
       "      <td>31</td>\n",
       "      <td>3.536</td>\n",
       "      <td>35</td>\n",
       "      <td>2.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYV</th>\n",
       "      <td>48</td>\n",
       "      <td>-1.414</td>\n",
       "      <td>31</td>\n",
       "      <td>2.121</td>\n",
       "      <td>42</td>\n",
       "      <td>-1.414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      (SE01, dk)  (SE01, deldk)  (AB01, dk)  (AB01, deldk)  (AB02, dk)  \\\n",
       "ADA           68          0.000          61          2.121          50   \n",
       "ADE           77          3.536          70         -4.243          67   \n",
       "ADF           67         -4.950          43          4.950          38   \n",
       "ADL           74         -5.657          43          7.778          53   \n",
       "AFD           28          1.414          18          1.414          22   \n",
       "...          ...            ...         ...            ...         ...   \n",
       "URAV          40          0.000          22          0.000          17   \n",
       "URB           52         -9.899          44          2.828          40   \n",
       "URX           89         -4.950          58          5.657          42   \n",
       "URYD          38          0.000          31          3.536          35   \n",
       "URYV          48         -1.414          31          2.121          42   \n",
       "\n",
       "      (AB02, deldk)  \n",
       "ADA           4.243  \n",
       "ADE          -2.121  \n",
       "ADF           2.828  \n",
       "ADL           6.364  \n",
       "AFD           1.414  \n",
       "...             ...  \n",
       "URAV          0.707  \n",
       "URB           7.071  \n",
       "URX           0.000  \n",
       "URYD          2.121  \n",
       "URYV         -1.414  \n",
       "\n",
       "[83 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''absolute del dk, eucledian distance of dk from symmetry line, Fig S1C '''\n",
    "\n",
    "deldk = pd.DataFrame()\n",
    "cons = np.sqrt(2)/2\n",
    "\n",
    "for name in ['SE01','AB01','AB02']:\n",
    "    deldk[name, 'dk']  = LRdfdeg.loc[:,(name,'Left')] + LRdfdeg.loc[:,(name,'Right')]\n",
    "    deldk[name,'deldk'] = round((LRdfdeg.loc[:,(name,'Left')] - LRdfdeg.loc[:,(name,'Right')])*cons,3)\n",
    "\n",
    "deldk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>se01</th>\n",
       "      <th>ab01</th>\n",
       "      <th>ab02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADAL-R</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADEL-R</th>\n",
       "      <td>0.402597</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.462687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADFL-R</th>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADLL-R</th>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.320755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFDL-R</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URAVL-R</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URBL-R</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URXL-R</th>\n",
       "      <td>0.483146</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYDL-R</th>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYVL-R</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             se01      ab01      ab02\n",
       "ADAL-R   0.352941  0.377049  0.320000\n",
       "ADEL-R   0.402597  0.428571  0.462687\n",
       "ADFL-R   0.492537  0.395349  0.421053\n",
       "ADLL-R   0.540541  0.348837  0.320755\n",
       "AFDL-R   0.428571  0.222222  0.363636\n",
       "...           ...       ...       ...\n",
       "URAVL-R  0.400000  0.181818  0.176471\n",
       "URBL-R   0.500000  0.409091  0.450000\n",
       "URXL-R   0.483146  0.379310  0.238095\n",
       "URYDL-R  0.526316  0.290323  0.200000\n",
       "URYVL-R  0.500000  0.290323  0.428571\n",
       "\n",
       "[83 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Fraction of unpaired synapses, fuk, of each neuron class, Fig 2B, 2C '''\n",
    "\n",
    "dic={}\n",
    "for df,name in zip([SE01_chem_asym,AB01_chem_asym,AB02_chem_asym],['se01','ab01','ab02']):\n",
    "    dic[name] = df[name+'-chem_frac_asym']\n",
    "\n",
    "fudf = pd.DataFrame.from_dict(dic,orient='index')\n",
    "fudf = fudf.T\n",
    "fudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">se01</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ab01</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ab02</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Left</th>\n",
       "      <th>Right</th>\n",
       "      <th>Left</th>\n",
       "      <th>Right</th>\n",
       "      <th>Left</th>\n",
       "      <th>Right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADAL-R</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADEL-R</th>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADFL-R</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADLL-R</th>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFDL-R</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URAVL-R</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URBL-R</th>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URXL-R</th>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYDL-R</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYVL-R</th>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        se01       ab01       ab02      \n",
       "        Left Right Left Right Left Right\n",
       "ADAL-R    12    12   13    10   11     5\n",
       "ADEL-R    18    13   12    18   14    17\n",
       "ADFL-R    13    20   12     5   10     6\n",
       "ADLL-R    16    24   13     2   13     4\n",
       "AFDL-R     7     5    3     1    5     3\n",
       "...      ...   ...  ...   ...  ...   ...\n",
       "URAVL-R    8     8    2     2    2     1\n",
       "URBL-R     6    20   11     7   14     4\n",
       "URXL-R    18    25   15     7    5     5\n",
       "URYDL-R   10    10    7     2    5     2\n",
       "URYVL-R   11    13    6     3    8    10\n",
       "\n",
       "[83 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' nukL and nukR, the number of unpaired synapses of the left vs. right member of each neuron class, Fig 2D'''\n",
    "\n",
    "nudic={}\n",
    "for df,name in zip([SE01_chem_asym,AB01_chem_asym,AB02_chem_asym],['se01','ab01','ab02']):\n",
    "    nudic[(name,'Left')] = df[name+'-L_chem_unilat_total']\n",
    "    nudic[(name,'Right')] = df[name+'-R_chem_unilat_total']\n",
    "\n",
    "nudf = pd.DataFrame.from_dict(nudic,orient='index')\n",
    "nudf = nudf.T\n",
    "nudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">SE01</th>\n",
       "      <th colspan=\"2\" halign=\"left\">AB01</th>\n",
       "      <th colspan=\"2\" halign=\"left\">AB02</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>nui</th>\n",
       "      <th>di</th>\n",
       "      <th>nui</th>\n",
       "      <th>di</th>\n",
       "      <th>nui</th>\n",
       "      <th>di</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADAL</th>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAR</th>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADEL</th>\n",
       "      <td>18.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADER</th>\n",
       "      <td>13.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADFL</th>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URXR</th>\n",
       "      <td>25.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYDL</th>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYDR</th>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYVL</th>\n",
       "      <td>11.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYVR</th>\n",
       "      <td>13.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SE01        AB01        AB02      \n",
       "        nui    di   nui    di   nui    di\n",
       "ADAL   12.0  34.0  13.0  32.0  11.0  28.0\n",
       "ADAR   12.0  34.0  10.0  29.0   5.0  22.0\n",
       "ADEL   18.0  41.0  12.0  32.0  14.0  32.0\n",
       "ADER   13.0  36.0  18.0  38.0  17.0  35.0\n",
       "ADFL   13.0  30.0  12.0  25.0  10.0  21.0\n",
       "...     ...   ...   ...   ...   ...   ...\n",
       "URXR   25.0  48.0   7.0  25.0   5.0  21.0\n",
       "URYDL  10.0  19.0   7.0  18.0   5.0  19.0\n",
       "URYDR  10.0  19.0   2.0  13.0   2.0  16.0\n",
       "URYVL  11.0  23.0   6.0  17.0   8.0  20.0\n",
       "URYVR  13.0  25.0   3.0  14.0  10.0  22.0\n",
       "\n",
       "[166 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Number of unpaired synapses of each individual neuron, nui, and  the neuron degree, di, Fig 3B\"\"\"\n",
    "dicnu={'SE01':{},'AB01':{},'AB02':{}}\n",
    "for df,name in zip([SE01_chem_asym,AB01_chem_asym,AB02_chem_asym],['se01','ab01','ab02']):\n",
    "    dicnu[name.upper()].update(dict(zip(df.index.str.replace('L-R','L'),df[name+'-L_chem_unilat_total'])))\n",
    "    dicnu[name.upper()].update(dict(zip(df.index.str.replace('L-R','R'),df[name+'-R_chem_unilat_total'])))\n",
    "\n",
    "indnudf = pd.DataFrame.from_dict(dicnu,orient='index')\n",
    "indnudf = indnudf.T\n",
    "degnudic ={}\n",
    "for name in ['SE01','AB01','AB02']:\n",
    "    degnudic[(name,'nui')] = indnudf[name]\n",
    "    degnudic[(name,'di')] = dfdeg[name]\n",
    "\n",
    "degnudf = pd.DataFrame.from_dict(degnudic,orient='index')\n",
    "degnudf = degnudf.T\n",
    "degnudf = degnudf.dropna(axis=0)\n",
    "degnudf = degnudf.sort_index()\n",
    "degnudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">SE01</th>\n",
       "      <th colspan=\"2\" halign=\"left\">AB01</th>\n",
       "      <th colspan=\"2\" halign=\"left\">AB02</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>undirected</th>\n",
       "      <th>directed</th>\n",
       "      <th>undirected</th>\n",
       "      <th>directed</th>\n",
       "      <th>undirected</th>\n",
       "      <th>directed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADAL</th>\n",
       "      <td>0.207</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADEL</th>\n",
       "      <td>0.457</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADFL</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADLL</th>\n",
       "      <td>0.464</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFDL</th>\n",
       "      <td>0.417</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URAVR</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URBR</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URXR</th>\n",
       "      <td>0.528</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYDR</th>\n",
       "      <td>0.471</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYVR</th>\n",
       "      <td>0.409</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            SE01                AB01                AB02         \n",
       "      undirected directed undirected directed undirected directed\n",
       "ADAL       0.207    0.353      0.385    0.406      0.370    0.393\n",
       "ADEL       0.457    0.439      0.321    0.375      0.393    0.438\n",
       "ADFL       0.435    0.433      0.476    0.480      0.389    0.476\n",
       "ADLL       0.464    0.485      0.409    0.481      0.360    0.419\n",
       "AFDL       0.417    0.467      0.375    0.300      0.222    0.417\n",
       "...          ...      ...        ...      ...        ...      ...\n",
       "URAVR      0.250    0.400      0.000    0.182      0.125    0.125\n",
       "URBR       0.538    0.606      0.278    0.350      0.231    0.267\n",
       "URXR       0.528    0.521      0.227    0.280      0.250    0.238\n",
       "URYDR      0.471    0.526      0.167    0.154      0.143    0.125\n",
       "URYVR      0.409    0.520      0.154    0.214      0.476    0.455\n",
       "\n",
       "[166 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Connectome individual neuron fraction of unpaired synapses, fuk, undirected vs. directed, Fig S2 \"\"\"\n",
    "fudic={('SE01','undirected'):{},('SE01','directed'):{},('AB01','undirected'):{},('AB01','directed'):{},('AB02','undirected'):{},('AB02','directed'):{}}\n",
    "\n",
    "for name,dir,und in zip(['se01','ab01','ab02'],[SE01_chem_asym,AB01_chem_asym,AB02_chem_asym],[se01_undi_frac_asym,ab01_undi_frac_asym,ab02_undi_frac_asym]):\n",
    "    for side in ['L','R']:\n",
    "        fudic[(name.upper(),'directed')].update(zip(dir.index.str.replace('L-R',side),round(dir[name+'-'+side+'_chem_unilat_total']/dir[name+'-deg_'+side],3)))\n",
    "        fudic[(name.upper(),'undirected')].update(zip(und.index.str.replace('L-R',side),round(und[name+'-'+side+'_unilat']/und[name+'-deg_'+side],3)))\n",
    "\n",
    "fudic\n",
    "fudirund = pd.DataFrame.from_dict(fudic,orient='index')\n",
    "fudirund = fudirund.T\n",
    "fudirund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "starting fu 0.8417871017871018\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "149\n",
      "starting fu 0.8969902319902321\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "180\n",
      "starting fu 0.8870598845598845\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "218\n",
      "starting fu 0.8361471861471863\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "226\n",
      "starting fu 0.9482167832167832\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "227\n",
      "starting fu 0.9471789321789323\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "240\n",
      "starting fu 0.8442027417027417\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "359\n",
      "starting fu 0.8540295815295815\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "379\n",
      "starting fu 0.8395299145299144\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "381\n",
      "starting fu 0.8911111111111112\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "396\n",
      "starting fu 0.8309487734487734\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "420\n",
      "starting fu 0.9211593961593962\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "562\n",
      "starting fu 0.9257070707070707\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "597\n",
      "starting fu 0.92495670995671\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "639\n",
      "starting fu 0.9510642135642137\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "660\n",
      "starting fu 0.9021453546453546\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "686\n",
      "starting fu 0.9092027417027417\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "742\n",
      "starting fu 0.9109188034188035\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "828\n",
      "starting fu 0.9347619047619048\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "908\n",
      "starting fu 0.8324231324231326\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "910\n",
      "starting fu 0.941686507936508\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">0.8</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0.3</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>undirected</th>\n",
       "      <th>directed</th>\n",
       "      <th>undirected</th>\n",
       "      <th>directed</th>\n",
       "      <th>undirected</th>\n",
       "      <th>directed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s149</th>\n",
       "      <td>0.849621</td>\n",
       "      <td>0.922625</td>\n",
       "      <td>0.338224</td>\n",
       "      <td>0.601106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.463452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s180</th>\n",
       "      <td>0.849199</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.336282</td>\n",
       "      <td>0.718016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.623750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s218</th>\n",
       "      <td>0.836854</td>\n",
       "      <td>0.956818</td>\n",
       "      <td>0.344881</td>\n",
       "      <td>0.704365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s226</th>\n",
       "      <td>0.837179</td>\n",
       "      <td>0.900437</td>\n",
       "      <td>0.349849</td>\n",
       "      <td>0.720980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s227</th>\n",
       "      <td>0.849129</td>\n",
       "      <td>0.900443</td>\n",
       "      <td>0.349026</td>\n",
       "      <td>0.803521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s240</th>\n",
       "      <td>0.842417</td>\n",
       "      <td>0.944762</td>\n",
       "      <td>0.347565</td>\n",
       "      <td>0.717615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s359</th>\n",
       "      <td>0.847650</td>\n",
       "      <td>0.976623</td>\n",
       "      <td>0.341022</td>\n",
       "      <td>0.618844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.599861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s379</th>\n",
       "      <td>0.840675</td>\n",
       "      <td>0.901627</td>\n",
       "      <td>0.328179</td>\n",
       "      <td>0.687284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.604901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s381</th>\n",
       "      <td>0.837540</td>\n",
       "      <td>0.949881</td>\n",
       "      <td>0.348533</td>\n",
       "      <td>0.630048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s396</th>\n",
       "      <td>0.808705</td>\n",
       "      <td>0.923419</td>\n",
       "      <td>0.340408</td>\n",
       "      <td>0.666421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s420</th>\n",
       "      <td>0.825624</td>\n",
       "      <td>0.850949</td>\n",
       "      <td>0.346271</td>\n",
       "      <td>0.816193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s562</th>\n",
       "      <td>0.836378</td>\n",
       "      <td>0.932103</td>\n",
       "      <td>0.349326</td>\n",
       "      <td>0.676344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.675476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s597</th>\n",
       "      <td>0.837381</td>\n",
       "      <td>0.893611</td>\n",
       "      <td>0.343462</td>\n",
       "      <td>0.484720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s639</th>\n",
       "      <td>0.842219</td>\n",
       "      <td>0.890750</td>\n",
       "      <td>0.344710</td>\n",
       "      <td>0.695025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s660</th>\n",
       "      <td>0.845009</td>\n",
       "      <td>0.938889</td>\n",
       "      <td>0.336875</td>\n",
       "      <td>0.738910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s686</th>\n",
       "      <td>0.845274</td>\n",
       "      <td>0.941270</td>\n",
       "      <td>0.345387</td>\n",
       "      <td>0.748473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.582289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s742</th>\n",
       "      <td>0.833366</td>\n",
       "      <td>0.940714</td>\n",
       "      <td>0.341172</td>\n",
       "      <td>0.743719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.656944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s828</th>\n",
       "      <td>0.827882</td>\n",
       "      <td>0.949838</td>\n",
       "      <td>0.342799</td>\n",
       "      <td>0.571769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s908</th>\n",
       "      <td>0.820280</td>\n",
       "      <td>0.953736</td>\n",
       "      <td>0.345288</td>\n",
       "      <td>0.879969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.565714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s910</th>\n",
       "      <td>0.849470</td>\n",
       "      <td>0.974242</td>\n",
       "      <td>0.348949</td>\n",
       "      <td>0.815244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.577321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0.8                  0.3                  0.0          \n",
       "     undirected  directed undirected  directed undirected  directed\n",
       "s149   0.849621  0.922625   0.338224  0.601106        0.0  0.463452\n",
       "s180   0.849199  1.000000   0.336282  0.718016        0.0  0.623750\n",
       "s218   0.836854  0.956818   0.344881  0.704365        0.0  0.641250\n",
       "s226   0.837179  0.900437   0.349849  0.720980        0.0  0.366429\n",
       "s227   0.849129  0.900443   0.349026  0.803521        0.0  0.538988\n",
       "s240   0.842417  0.944762   0.347565  0.717615        0.0  0.660952\n",
       "s359   0.847650  0.976623   0.341022  0.618844        0.0  0.599861\n",
       "s379   0.840675  0.901627   0.328179  0.687284        0.0  0.604901\n",
       "s381   0.837540  0.949881   0.348533  0.630048        0.0  0.645806\n",
       "s396   0.808705  0.923419   0.340408  0.666421        0.0  0.488333\n",
       "s420   0.825624  0.850949   0.346271  0.816193        0.0  0.641429\n",
       "s562   0.836378  0.932103   0.349326  0.676344        0.0  0.675476\n",
       "s597   0.837381  0.893611   0.343462  0.484720        0.0  0.733393\n",
       "s639   0.842219  0.890750   0.344710  0.695025        0.0  0.538333\n",
       "s660   0.845009  0.938889   0.336875  0.738910        0.0  0.511270\n",
       "s686   0.845274  0.941270   0.345387  0.748473        0.0  0.582289\n",
       "s742   0.833366  0.940714   0.341172  0.743719        0.0  0.656944\n",
       "s828   0.827882  0.949838   0.342799  0.571769        0.0  0.538790\n",
       "s908   0.820280  0.953736   0.345288  0.879969        0.0  0.565714\n",
       "s910   0.849470  0.974242   0.348949  0.815244        0.0  0.577321"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Small random networks (40 neurons 80 synapses), fu unidrected vs directed, Fig 4Bi\"\"\"\n",
    "\n",
    "class_count = class_info('herm')[3]\n",
    "two_neuron_classes = []\n",
    "for key,val in class_count.items():\n",
    "    if val == 2:\n",
    "        two_neuron_classes.append(key)\n",
    "\n",
    "toy_nodes = []\n",
    "ex_nodes = []\n",
    "\n",
    "edges=80\n",
    "classes = 20\n",
    "nodes = classes*2\n",
    "for label in two_neuron_classes[:classes]:\n",
    "    for side in ('L','R'):\n",
    "        toy_nodes.append(str(label)+side)\n",
    "for label in ['A','B','C','D','E','F','G','H','I','J']:\n",
    "    for side in ('L','R'):\n",
    "        ex_nodes.append(label+side)\n",
    "toy_nodes_dict = dict(zip(ex_nodes,toy_nodes))\n",
    "er_toy4net_dic = {}\n",
    "\n",
    "''' toy networks'''\n",
    "seed = 0\n",
    "while len(er_toy4net_dic)<21*3:\n",
    "    random.seed(seed)\n",
    "    er_toy = nx.erdos_renyi_graph(len(toy_nodes),p=0.1)\n",
    "    if (len(er_toy.nodes()) == nodes) and (len(er_toy.edges()) == edges) and nx.is_connected(er_toy):\n",
    "        print(seed)\n",
    "        er_toy = nx.relabel_nodes(er_toy,dict(zip(er_toy.nodes(),toy_nodes)),copy=True)\n",
    "        ertoy_tosym = er_toy.copy(); ertoy_toasym = er_toy.copy()\n",
    "        ertoy_undi_symasymed = symmetrize_asymmetrize_network(ertoy_toasym,ertoy_tosym,seed=0,network_size='small')\n",
    "        for fu in ['0.0','0.3','0.8']:\n",
    "            ertoy_atfu = nx.from_dict_of_lists(ertoy_undi_symasymed[fu]['net'])\n",
    "            ertoy_atfu_dir = undirected_to_directed_random(ertoy_atfu)\n",
    "            er_toy4net_dic[('s'+str(seed),fu,'fu')] = {'undirected':fractional_asymmetry_undirected(ertoy_atfu)[0],'directed':fractional_asymmetry_directed(ertoy_atfu_dir)[0]}\n",
    "\n",
    "    seed+=1\n",
    "er_toy4net_df = pd.DataFrame.from_dict(er_toy4net_dic,orient='index')\n",
    "er_toy4net_df = er_toy4net_df.droplevel(level=2,axis=0)\n",
    "\n",
    "er_toy4net_df = er_toy4net_df.stack()\n",
    "er_toy4net_df = er_toy4net_df.swaplevel(1,2)\n",
    "\n",
    "er_toy4net_df = er_toy4net_df.unstack(0).T\n",
    "er_toy4net_df = er_toy4net_df.swaplevel(0,1,axis=1)\n",
    "er_toy4net_df = er_toy4net_df.sort_index(axis=1,level=0,ascending=False)\n",
    "er_toy4net_df = er_toy4net_df.drop('s23')\n",
    "er_toy4net_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s149</th>\n",
       "      <td>0.463452</td>\n",
       "      <td>0.262882</td>\n",
       "      <td>0.073004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s180</th>\n",
       "      <td>0.623750</td>\n",
       "      <td>0.381734</td>\n",
       "      <td>0.150801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s218</th>\n",
       "      <td>0.641250</td>\n",
       "      <td>0.359484</td>\n",
       "      <td>0.119964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s226</th>\n",
       "      <td>0.366429</td>\n",
       "      <td>0.371131</td>\n",
       "      <td>0.063258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s227</th>\n",
       "      <td>0.538988</td>\n",
       "      <td>0.454495</td>\n",
       "      <td>0.051313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s240</th>\n",
       "      <td>0.660952</td>\n",
       "      <td>0.370051</td>\n",
       "      <td>0.102345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s359</th>\n",
       "      <td>0.599861</td>\n",
       "      <td>0.277822</td>\n",
       "      <td>0.128973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s379</th>\n",
       "      <td>0.604901</td>\n",
       "      <td>0.359105</td>\n",
       "      <td>0.060952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s381</th>\n",
       "      <td>0.645806</td>\n",
       "      <td>0.281515</td>\n",
       "      <td>0.112341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s396</th>\n",
       "      <td>0.488333</td>\n",
       "      <td>0.326014</td>\n",
       "      <td>0.114714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s420</th>\n",
       "      <td>0.641429</td>\n",
       "      <td>0.469922</td>\n",
       "      <td>0.025325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s562</th>\n",
       "      <td>0.675476</td>\n",
       "      <td>0.327019</td>\n",
       "      <td>0.095725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s597</th>\n",
       "      <td>0.733393</td>\n",
       "      <td>0.141259</td>\n",
       "      <td>0.056230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s639</th>\n",
       "      <td>0.538333</td>\n",
       "      <td>0.350316</td>\n",
       "      <td>0.048532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s660</th>\n",
       "      <td>0.511270</td>\n",
       "      <td>0.402034</td>\n",
       "      <td>0.093880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s686</th>\n",
       "      <td>0.582289</td>\n",
       "      <td>0.403086</td>\n",
       "      <td>0.095996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s742</th>\n",
       "      <td>0.656944</td>\n",
       "      <td>0.402547</td>\n",
       "      <td>0.107348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s828</th>\n",
       "      <td>0.538790</td>\n",
       "      <td>0.228970</td>\n",
       "      <td>0.121955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s908</th>\n",
       "      <td>0.565714</td>\n",
       "      <td>0.534681</td>\n",
       "      <td>0.133456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s910</th>\n",
       "      <td>0.577321</td>\n",
       "      <td>0.466295</td>\n",
       "      <td>0.124773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0.0       0.3       0.8\n",
       "s149  0.463452  0.262882  0.073004\n",
       "s180  0.623750  0.381734  0.150801\n",
       "s218  0.641250  0.359484  0.119964\n",
       "s226  0.366429  0.371131  0.063258\n",
       "s227  0.538988  0.454495  0.051313\n",
       "s240  0.660952  0.370051  0.102345\n",
       "s359  0.599861  0.277822  0.128973\n",
       "s379  0.604901  0.359105  0.060952\n",
       "s381  0.645806  0.281515  0.112341\n",
       "s396  0.488333  0.326014  0.114714\n",
       "s420  0.641429  0.469922  0.025325\n",
       "s562  0.675476  0.327019  0.095725\n",
       "s597  0.733393  0.141259  0.056230\n",
       "s639  0.538333  0.350316  0.048532\n",
       "s660  0.511270  0.402034  0.093880\n",
       "s686  0.582289  0.403086  0.095996\n",
       "s742  0.656944  0.402547  0.107348\n",
       "s828  0.538790  0.228970  0.121955\n",
       "s908  0.565714  0.534681  0.133456\n",
       "s910  0.577321  0.466295  0.124773"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Small random networks (40 neurons 80 synapses), difference between directed and undirected fu, Fig 4Bii\"\"\"\n",
    "\n",
    "diffdic = {}\n",
    "for fu in ['0.0','0.3','0.8']:\n",
    "    diff = er_toy4net_df[(fu,'directed')] - er_toy4net_df[(fu,'undirected')]\n",
    "    diffdic[fu] = diff\n",
    "\n",
    "er_toy4net_diff_df = pd.DataFrame.from_dict(diffdic,orient='index')\n",
    "er_toy4net_diff_df =er_toy4net_diff_df.T\n",
    "er_toy4net_diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "starting fu 0.8417871017871018\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "149\n",
      "starting fu 0.8969902319902321\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "180\n",
      "starting fu 0.8870598845598845\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "218\n",
      "starting fu 0.8361471861471863\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "226\n",
      "starting fu 0.9482167832167832\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "227\n",
      "starting fu 0.9471789321789323\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "240\n",
      "starting fu 0.8442027417027417\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "359\n",
      "starting fu 0.8540295815295815\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "379\n",
      "starting fu 0.8395299145299144\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "381\n",
      "starting fu 0.8911111111111112\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "396\n",
      "starting fu 0.8309487734487734\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "420\n",
      "starting fu 0.9211593961593962\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "562\n",
      "starting fu 0.9257070707070707\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "597\n",
      "starting fu 0.92495670995671\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "639\n",
      "starting fu 0.9510642135642137\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "660\n",
      "starting fu 0.9021453546453546\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "686\n",
      "starting fu 0.9092027417027417\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "742\n",
      "starting fu 0.9109188034188035\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "828\n",
      "starting fu 0.9347619047619048\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "908\n",
      "starting fu 0.8324231324231326\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n",
      "910\n",
      "starting fu 0.941686507936508\n",
      "asymmetrization started\n",
      "asymmetrization done\n",
      "symmetrization started\n",
      "symmetrization done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>K</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <th>P</th>\n",
       "      <th>Q</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"20\" valign=\"top\">undirected</th>\n",
       "      <th>s910</th>\n",
       "      <td>0.714</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s908</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s828</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s742</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s686</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s660</th>\n",
       "      <td>0.273</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s639</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s597</th>\n",
       "      <td>0.273</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s562</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s420</th>\n",
       "      <td>0.692</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.167</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s396</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s381</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s379</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s359</th>\n",
       "      <td>0.273</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s240</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s227</th>\n",
       "      <td>0.467</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s226</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s218</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s180</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s149</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.385</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"20\" valign=\"top\">directed</th>\n",
       "      <th>s910</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.778</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.733</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.714</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s908</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.778</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.636</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.556</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.846</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s828</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.455</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.400</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.818</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s742</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s686</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.714</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.882</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s660</th>\n",
       "      <td>0.636</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.778</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s639</th>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.818</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s597</th>\n",
       "      <td>0.636</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.846</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.846</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s562</th>\n",
       "      <td>0.692</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.818</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s420</th>\n",
       "      <td>0.846</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.429</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s396</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s381</th>\n",
       "      <td>0.400</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.833</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.833</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s379</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.818</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s359</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.846</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.818</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.714</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s240</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.636</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s227</th>\n",
       "      <td>0.733</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.778</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s226</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.778</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.571</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.647</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s218</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.778</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s180</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.714</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s149</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.538</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.429</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A      B      C      D      E      F      G      H  \\\n",
       "undirected s910  0.714  0.500  0.333  0.556  0.333  0.000  0.000  0.818   \n",
       "           s908  0.333  0.200  0.692  0.000  0.200  0.556  0.500  0.273   \n",
       "           s828  0.250  0.000  0.091  0.500  0.800  0.750  0.000  0.529   \n",
       "           s742  0.333  0.400  0.000  0.500  0.333  0.200  0.571  0.200   \n",
       "           s686  0.500  0.000  0.667  0.000  0.000  0.429  0.000  0.200   \n",
       "           s660  0.273  0.556  0.000  0.455  0.538  0.333  0.000  0.833   \n",
       "           s639  0.200  0.000  0.636  0.556  0.625  0.000  0.600  0.400   \n",
       "           s597  0.273  0.000  0.000  0.000  0.000  0.750  0.600  0.692   \n",
       "           s562  0.538  0.333  0.400  0.455  0.000  0.250  0.833  0.333   \n",
       "           s420  0.692  0.429  0.833  0.000  0.000  0.143  0.200  0.500   \n",
       "           s396  0.000  0.333  0.600  0.000  0.000  0.000  0.556  0.333   \n",
       "           s381  0.200  0.333  0.000  0.200  0.692  0.455  0.500  0.000   \n",
       "           s379  0.000  0.000  0.429  0.333  0.600  0.000  0.636  0.333   \n",
       "           s359  0.273  0.400  0.818  0.143  0.429  0.200  0.692  0.000   \n",
       "           s240  0.000  0.200  0.400  0.429  0.500  0.273  0.000  0.000   \n",
       "           s227  0.467  0.000  0.500  0.000  0.571  0.400  0.600  0.000   \n",
       "           s226  0.200  0.250  0.500  0.000  0.500  0.400  0.333  0.818   \n",
       "           s218  0.500  0.333  0.000  0.400  0.333  0.500  0.600  0.600   \n",
       "           s180  0.600  0.429  0.000  0.000  0.600  0.429  0.400  0.333   \n",
       "           s149  0.000  0.385  1.000  0.333  0.200  0.429  0.600  0.200   \n",
       "directed   s910  1.000  1.000  0.667  0.778  1.000  0.000  0.500  1.000   \n",
       "           s908  0.333  0.200  0.692  0.667  0.800  0.778  1.000  0.636   \n",
       "           s828  0.500  0.500  0.455  1.000  1.000  1.000  0.000  0.882   \n",
       "           s742  1.000  0.600  0.000  0.750  0.833  0.600  0.857  0.600   \n",
       "           s686  0.667  0.500  0.667  0.500  1.000  0.714  1.000  0.333   \n",
       "           s660  0.636  0.556  0.333  0.818  0.846  0.333  1.000  1.000   \n",
       "           s639  0.600  1.000  0.818  1.000  0.625  0.333  1.000  0.600   \n",
       "           s597  0.636  0.500  1.000  0.000  0.000  1.000  0.800  0.846   \n",
       "           s562  0.692  0.667  0.600  0.818  1.000  0.750  1.000  0.833   \n",
       "           s420  0.846  1.000  1.000  0.000  0.000  0.429  1.000  0.750   \n",
       "           s396  0.500  0.556  0.733  0.500  0.500  0.000  0.778  0.667   \n",
       "           s381  0.400  1.000  1.000  1.000  0.692  0.636  0.833  0.500   \n",
       "           s379  0.000  1.000  1.000  0.333  0.867  0.000  0.818  1.000   \n",
       "           s359  0.455  0.800  0.818  0.714  0.714  0.467  0.846  1.000   \n",
       "           s240  0.500  0.600  0.600  0.714  0.500  0.636  1.000  0.333   \n",
       "           s227  0.733  0.667  1.000  1.000  0.714  0.800  1.000  0.500   \n",
       "           s226  0.200  0.750  1.000  0.667  0.500  1.000  0.778  1.000   \n",
       "           s218  0.500  0.778  1.000  0.600  1.000  0.750  0.600  1.000   \n",
       "           s180  1.000  0.857  1.000  1.000  0.800  0.714  0.600  0.667   \n",
       "           s149  1.000  0.538  1.000  1.000  0.200  0.571  0.600  0.200   \n",
       "\n",
       "                     I      J      K      L      M      N      O      P  \\\n",
       "undirected s910  0.733  0.000  0.385  0.000  0.333  0.000  0.733  0.800   \n",
       "           s908  0.714  0.333  0.000  0.200  0.000  0.800  0.429  0.692   \n",
       "           s828  0.000  0.429  0.556  0.429  0.200  0.000  0.500  0.636   \n",
       "           s742  0.333  0.556  0.000  0.818  0.000  0.333  0.273  0.000   \n",
       "           s686  0.647  0.333  0.556  0.333  0.500  0.000  0.538  0.571   \n",
       "           s660  0.250  0.800  0.636  0.000  0.000  0.333  0.429  0.250   \n",
       "           s639  0.500  0.600  0.200  0.200  0.000  0.091  0.250  0.800   \n",
       "           s597  0.750  0.500  0.500  0.000  0.200  0.455  0.000  0.538   \n",
       "           s562  0.750  0.667  0.000  0.200  0.429  0.000  0.636  0.429   \n",
       "           s420  0.400  0.000  0.429  0.500  0.000  0.500  0.167  1.000   \n",
       "           s396  0.455  0.500  0.200  0.667  0.143  0.091  0.571  0.800   \n",
       "           s381  0.200  0.500  0.000  0.667  0.000  0.429  0.200  0.333   \n",
       "           s379  0.636  0.500  0.600  0.400  0.579  0.000  0.333  0.000   \n",
       "           s359  0.500  0.000  0.500  0.818  0.333  1.000  0.000  0.000   \n",
       "           s240  0.200  0.800  0.667  0.200  0.250  0.500  0.667  0.000   \n",
       "           s227  0.455  0.455  0.333  0.333  0.000  0.556  0.333  0.333   \n",
       "           s226  0.286  0.833  0.412  0.000  0.000  0.556  0.667  0.636   \n",
       "           s218  0.467  0.800  0.000  0.000  0.143  0.600  0.000  0.429   \n",
       "           s180  0.000  0.143  0.556  0.571  0.500  0.692  0.000  0.429   \n",
       "           s149  0.273  0.143  0.500  0.200  0.286  0.333  0.750  0.333   \n",
       "directed   s910  1.000  1.000  0.692  0.500  0.733  1.000  0.733  0.800   \n",
       "           s908  1.000  0.556  1.000  0.200  0.000  1.000  0.857  0.846   \n",
       "           s828  0.000  0.714  0.778  0.429  0.400  1.000  0.667  0.818   \n",
       "           s742  1.000  0.778  0.000  0.818  0.667  0.667  1.000  0.500   \n",
       "           s686  0.882  1.000  0.778  0.333  1.000  1.000  0.692  0.857   \n",
       "           s660  1.000  1.000  1.000  0.000  0.500  0.778  1.000  0.250   \n",
       "           s639  0.750  1.000  0.600  0.200  0.000  0.818  0.500  0.800   \n",
       "           s597  1.000  1.000  0.875  1.000  0.600  0.818  0.667  0.846   \n",
       "           s562  0.750  0.667  0.667  0.200  0.429  0.000  0.818  0.714   \n",
       "           s420  0.800  1.000  1.000  1.000  0.500  0.750  0.667  1.000   \n",
       "           s396  1.000  1.000  0.200  0.833  0.429  0.273  0.857  0.800   \n",
       "           s381  0.600  0.833  1.000  0.667  0.500  1.000  1.000  0.667   \n",
       "           s379  0.818  0.667  0.600  0.600  0.789  0.500  0.778  0.000   \n",
       "           s359  0.500  1.000  1.000  0.818  1.000  1.000  1.000  1.000   \n",
       "           s240  1.000  0.800  0.833  0.600  0.500  0.500  1.000  1.000   \n",
       "           s227  0.636  0.818  0.667  1.000  0.000  0.778  0.667  0.778   \n",
       "           s226  0.571  1.000  0.647  1.000  0.000  0.778  0.833  0.636   \n",
       "           s218  1.000  0.800  0.000  0.667  0.143  0.800  1.000  1.000   \n",
       "           s180  0.500  0.714  1.000  0.857  1.000  0.846  0.667  0.714   \n",
       "           s149  0.636  0.429  0.750  0.600  0.429  1.000  1.000  0.667   \n",
       "\n",
       "                     Q      R      S      T  \n",
       "undirected s910  0.429  0.000  0.111  0.200  \n",
       "           s908  0.250  0.000  0.400  0.333  \n",
       "           s828  0.818  0.000  0.000  0.368  \n",
       "           s742  0.556  0.667  0.750  0.000  \n",
       "           s686  0.333  0.600  0.500  0.200  \n",
       "           s660  0.000  0.333  0.385  0.333  \n",
       "           s639  0.400  0.200  0.000  0.636  \n",
       "           s597  0.538  0.200  0.600  0.273  \n",
       "           s562  0.400  0.333  0.000  0.000  \n",
       "           s420  0.250  0.429  0.455  0.000  \n",
       "           s396  0.333  0.833  0.143  0.250  \n",
       "           s381  0.333  0.429  0.500  1.000  \n",
       "           s379  0.600  0.250  0.000  0.333  \n",
       "           s359  0.429  0.000  0.000  0.286  \n",
       "           s240  0.200  1.000  0.333  0.333  \n",
       "           s227  0.778  0.000  0.667  0.200  \n",
       "           s226  0.000  0.273  0.000  0.333  \n",
       "           s218  0.467  0.143  0.250  0.333  \n",
       "           s180  0.600  0.111  0.000  0.333  \n",
       "           s149  0.200  0.000  0.000  0.600  \n",
       "directed   s910  0.714  1.000  0.778  0.600  \n",
       "           s908  1.000  0.667  0.600  1.000  \n",
       "           s828  1.000  1.000  1.000  0.684  \n",
       "           s742  0.667  0.833  0.750  0.333  \n",
       "           s686  0.667  0.600  1.000  0.200  \n",
       "           s660  1.000  0.833  0.385  0.333  \n",
       "           s639  1.000  0.600  0.667  0.818  \n",
       "           s597  1.000  1.000  1.000  0.636  \n",
       "           s562  0.800  0.500  0.500  0.000  \n",
       "           s420  0.750  0.714  0.818  0.000  \n",
       "           s396  0.667  1.000  0.143  0.750  \n",
       "           s381  1.000  0.857  0.833  1.000  \n",
       "           s379  0.600  1.000  0.500  0.833  \n",
       "           s359  0.714  1.000  1.000  0.571  \n",
       "           s240  1.000  1.000  0.778  0.556  \n",
       "           s227  1.000  1.000  1.000  0.600  \n",
       "           s226  0.000  0.818  0.500  1.000  \n",
       "           s218  0.600  0.429  0.750  1.000  \n",
       "           s180  0.800  0.556  0.000  0.833  \n",
       "           s149  1.000  0.500  1.000  0.733  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Small random networks (40 neurons 80 synapses), neuron class fraction of unpaired synapses fuk undirected vs. directed networks, Fig 4Biii\"\"\"\n",
    "\n",
    "class_count = class_info('herm')[3]\n",
    "two_neuron_classes = []\n",
    "for key,val in class_count.items():\n",
    "    if val == 2:\n",
    "        two_neuron_classes.append(key)\n",
    "\n",
    "toy_nodes = []\n",
    "ex_nodes = []\n",
    "\n",
    "edges=80\n",
    "classes = 20\n",
    "nodes = classes*2\n",
    "for label in two_neuron_classes[:classes]:\n",
    "    for side in ('L','R'):\n",
    "        toy_nodes.append(str(label)+side)\n",
    "toy_nodes_dict = dict(zip(list(set([n[:-1]+'L-R' for n in toy_nodes])),[i.upper() for i in list(map(chr, range(97, 117)))]))\n",
    "toy_nodes_dict\n",
    "\n",
    "er_toy4net_03_dic = {}\n",
    "\n",
    "''' toy networks'''\n",
    "seed = 0\n",
    "while len(er_toy4net_03_dic)<21*2:\n",
    "    random.seed(seed)\n",
    "    er_toy = nx.erdos_renyi_graph(len(toy_nodes),p=0.1)\n",
    "    if (len(er_toy.nodes()) == nodes) and (len(er_toy.edges()) == edges) and nx.is_connected(er_toy):\n",
    "        print(seed)\n",
    "        er_toy = nx.relabel_nodes(er_toy,dict(zip(er_toy.nodes(),toy_nodes)),copy=True)\n",
    "        ertoy_tosym = er_toy.copy(); ertoy_toasym = er_toy.copy()\n",
    "        ertoy_undi_symasymed = symmetrize_asymmetrize_network(ertoy_toasym,ertoy_tosym,seed=0,network_size='small')\n",
    "        ertoy_atfu = nx.from_dict_of_lists(ertoy_undi_symasymed['0.3']['net'])\n",
    "        er_toy4net_03_dic[('s'+str(seed),'undirected')] = dict(zip(fractional_asymmetry_undirected(ertoy_atfu)[1].index,fractional_asymmetry_undirected(ertoy_atfu)[1]['frac_asym']))\n",
    "        ertoy_atfu_dir = undirected_to_directed_random(ertoy_atfu)\n",
    "        er_toy4net_03_dic[('s'+str(seed),'directed')] = dict(zip(fractional_asymmetry_directed(ertoy_atfu_dir)[1].index,fractional_asymmetry_directed(ertoy_atfu_dir)[1][0]))\n",
    "\n",
    "    seed+=1\n",
    "\n",
    "er_toy4net_03_dic\n",
    "\n",
    "er_toy4net_03_df = pd.DataFrame.from_dict(er_toy4net_03_dic,orient='index')\n",
    "er_toy4net_03_df = er_toy4net_03_df.T\n",
    "er_toy4net_03_df = er_toy4net_03_df.swaplevel(0,1,axis=1).sort_index(axis=1)\n",
    "er_toy4net_03_df.rename(toy_nodes_dict,axis=0,inplace=True)\n",
    "er_toy4net_03_df = er_toy4net_03_df.T\n",
    "er_toy4net_03_df = er_toy4net_03_df.drop('s23',axis=0,level=1)\n",
    "er_toy4net_03_df = er_toy4net_03_df.sort_index(axis=1).sort_index(axis=0,ascending=False)\n",
    "er_toy4net_03_df = round(er_toy4net_03_df,3)\n",
    "er_toy4net_03_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directed\n",
      "CeH1c 0.4322887988702395\n",
      "CeH2c 0.36900078833333944\n",
      "CeH3c 0.34429208553878926\n",
      "undirected\n",
      "CeH1c 0.3559518072289157\n",
      "CeH2c 0.3249156626506024\n",
      "CeH3c 0.3009638554216867\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Connectome fraction of unpaired synpases undirected vs. directed network, Fig 4C \"\"\"\n",
    "print('directed')\n",
    "for df,name, label in zip([SE01_chem_asym,AB01_chem_asym,AB02_chem_asym],['se01','ab01','ab02'],['CeH1c','CeH2c','CeH3c']):\n",
    "    print(label,np.mean(df[name+'-chem_frac_asym']))\n",
    "print('undirected')\n",
    "for df,name, label in zip([se01_undi_frac_asym,ab01_undi_frac_asym,ab02_undi_frac_asym],['se01','ab01','ab02'],['CeH1c','CeH2c','CeH3c']):\n",
    "    print(label,np.mean(df[name+'-frac_asym']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">CeH1c</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CeH2c</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CeH3c</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>undirected</th>\n",
       "      <th>directed</th>\n",
       "      <th>undirected</th>\n",
       "      <th>directed</th>\n",
       "      <th>undirected</th>\n",
       "      <th>directed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADAL-R</th>\n",
       "      <td>0.220</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADEL-R</th>\n",
       "      <td>0.387</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADFL-R</th>\n",
       "      <td>0.447</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADLL-R</th>\n",
       "      <td>0.483</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFDL-R</th>\n",
       "      <td>0.364</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URAVL-R</th>\n",
       "      <td>0.226</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URBL-R</th>\n",
       "      <td>0.442</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URXL-R</th>\n",
       "      <td>0.493</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYDL-R</th>\n",
       "      <td>0.419</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URYVL-R</th>\n",
       "      <td>0.381</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             CeH1c               CeH2c               CeH3c         \n",
       "        undirected directed undirected directed undirected directed\n",
       "ADAL-R       0.220    0.353      0.360    0.377      0.292    0.320\n",
       "ADEL-R       0.387    0.403      0.377    0.429      0.414    0.463\n",
       "ADFL-R       0.447    0.493      0.405    0.395      0.312    0.421\n",
       "ADLL-R       0.483    0.541      0.297    0.349      0.273    0.321\n",
       "AFDL-R       0.364    0.429      0.286    0.222      0.222    0.364\n",
       "...            ...      ...        ...      ...        ...      ...\n",
       "URAVL-R      0.226    0.400      0.048    0.182      0.125    0.176\n",
       "URBL-R       0.442    0.500      0.333    0.409      0.412    0.450\n",
       "URXL-R       0.493    0.483      0.261    0.379      0.273    0.238\n",
       "URYDL-R      0.419    0.526      0.259    0.290      0.200    0.200\n",
       "URYVL-R      0.381    0.500      0.241    0.290      0.421    0.429\n",
       "\n",
       "[83 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Connectome neuron class fraction of unpaired synapses, fuk, undirected vs. directed, Fig 4D\"\"\"\n",
    "\n",
    "dirdfs = [SE01_chem_asym,AB01_chem_asym,AB02_chem_asym]\n",
    "unddfs = [se01_undi_frac_asym,ab01_undi_frac_asym,ab02_undi_frac_asym]\n",
    "fuinddic = {}\n",
    "\n",
    "for dir, und, name, label in zip(dirdfs,unddfs,['se01','ab01','ab02'],['CeH1c','CeH2c','CeH3c']):\n",
    "    und_asym = dict(zip(und.index,und[name+'-frac_asym']))\n",
    "    dir_asym = dict(zip(dir.index,round(dir[name+'-chem_frac_asym'],3)))\n",
    "    fuinddic[(label,'undirected')] = und_asym\n",
    "    fuinddic[(label,'directed')] = dir_asym\n",
    "\n",
    "fuinddf = pd.DataFrame.from_dict(fuinddic,orient='index')\n",
    "fuinddf = fuinddf.T\n",
    "fuinddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">CeH1c</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CeH2c</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CeH3c</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>undirected</th>\n",
       "      <th>directed</th>\n",
       "      <th>undirected</th>\n",
       "      <th>directed</th>\n",
       "      <th>undirected</th>\n",
       "      <th>directed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>individual neuron</th>\n",
       "      <td>2.071570</td>\n",
       "      <td>2.478243</td>\n",
       "      <td>2.206269</td>\n",
       "      <td>2.881241</td>\n",
       "      <td>2.217753</td>\n",
       "      <td>2.841263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neuron class</th>\n",
       "      <td>1.744655</td>\n",
       "      <td>1.970491</td>\n",
       "      <td>1.870220</td>\n",
       "      <td>2.258752</td>\n",
       "      <td>1.886179</td>\n",
       "      <td>2.269102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       CeH1c                CeH2c                CeH3c  \\\n",
       "                  undirected  directed undirected  directed undirected   \n",
       "individual neuron   2.071570  2.478243   2.206269  2.881241   2.217753   \n",
       "neuron class        1.744655  1.970491   1.870220  2.258752   1.886179   \n",
       "\n",
       "                             \n",
       "                   directed  \n",
       "individual neuron  2.841263  \n",
       "neuron class       2.269102  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Connectome mean shortest path, SP, for neuron network and class network Fig 5D\"\"\"\n",
    "\n",
    "dirnet = [se01_chem_net,ab01_chem_net,ab02_chem_net]\n",
    "undnet = [se01_undi_net,ab01_undi_net,ab02_undi_net]\n",
    "names = ['CeH1c','CeH2c','CeH3c']\n",
    "\n",
    "spdic = {}\n",
    "\n",
    "for und,dir,name in zip(undnet,dirnet,names):\n",
    "    claund = network_neuron_classes(und,directed=False,sex='herm')\n",
    "    cladir = network_neuron_classes(dir,directed=True,sex='herm')\n",
    "    und = {'individual neuron':nx.average_shortest_path_length(und),'neuron class':nx.average_shortest_path_length(claund)}\n",
    "    dir = {'individual neuron':get_average_shortest_directed_path_length(dir),'neuron class':get_average_shortest_directed_path_length(cladir)}\n",
    "    spdic[(name,'undirected')] = und\n",
    "    spdic[(name,'directed')] = dir\n",
    "\n",
    "spdf = pd.DataFrame.from_dict(spdic,orient='index')\n",
    "spdf = spdf.T\n",
    "spdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fu</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>SP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sym</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.536</td>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid</th>\n",
       "      <td>0.41875</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.857</td>\n",
       "      <td>2.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asym</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.786</td>\n",
       "      <td>3.308333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Fu     R1     R2     R3     S1     S2     S3        SP\n",
       "sym   0.00000  0.500  0.321  0.250  0.571  0.125  0.536  3.333333\n",
       "mid   0.41875  0.396  0.429  0.163  0.714  0.077  0.857  2.775000\n",
       "asym  1.00000  0.317  0.536  0.172  0.571  0.096  0.786  3.308333"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Simple model (example) network, Redundancy Rn, Reachability, Sn, and mean shortest path, SP vs.  fraction of unpaired synapses, fu, Fig 5E, 5F\"\"\"\n",
    "\n",
    "f = open(folder_path+'/input_files/celegans_class_count_commonSE01AB01AB02.json','r')\n",
    "LR_class_count = json.load(f)\n",
    "\n",
    "two_neuron_classes = []\n",
    "for key,val in LR_class_count.items():\n",
    "    if val == 2:\n",
    "        two_neuron_classes.append(key)\n",
    "LR_classes = pd.read_csv(folder_path+'/input_files/celegans_LR_neurons_classes_commonSE01AB01AB02.csv',header=None)\n",
    "LR_classes = list(LR_classes[0])\n",
    "toy_nodes = []\n",
    "ex_nodes = []\n",
    "\n",
    "classes = 8\n",
    "nodes = classes*2\n",
    "edges=80\n",
    "for label in two_neuron_classes[:classes]:\n",
    "    for side in ('L','R'):\n",
    "        toy_nodes.append(str(label)+side)\n",
    "for label in ['A','B','C','D','E','F','G','H']:\n",
    "    for side in ('L','R'):\n",
    "        ex_nodes.append(label+side)\n",
    "toy_nodes_dict = dict(zip(toy_nodes,ex_nodes))\n",
    "\n",
    "exsym = nx.read_gml(folder_path+'/network_files/er_example_sym.gml')\n",
    "exmid = nx.read_gml(folder_path+'/network_files/er_example_half.gml')\n",
    "exasym = nx.read_gml(folder_path+'/network_files/er_example_asym.gml')\n",
    "\n",
    "infdic = {}\n",
    "for net,name in zip([exsym,exmid,exasym],['sym','mid','asym']):\n",
    "    rs = [fractional_asymmetry_undirected(net)[0]]\n",
    "    for pl in range(1,4):\n",
    "        r,s = redundancy_diversity(net,pl,directed=False,sex='herm')\n",
    "        rs.extend([r,s])\n",
    "    rs.append(nx.average_shortest_path_length(net))\n",
    "    infdic[name] = rs\n",
    "columns=['Fu','R1','R2','R3','S1','S2','S3','SP']\n",
    "infdf = pd.DataFrame.from_dict(infdic,orient='index',columns=columns)\n",
    "infdf\n",
    "# exsym = nx.relabel_nodes(exsym,toy_nodes_dict,copy=True)\n",
    "# exmid = nx.relabel_nodes(exmid,toy_nodes_dict,copy=True)\n",
    "# exasym = nx.relabel_nodes(exasym,toy_nodes_dict,copy=True)\n",
    "\n",
    "\n",
    "# exmid.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CeH1c 0.3559905915262085 0.407 0.328\n",
      "CeH2c 0.3249516596414129 0.431 0.266\n",
      "CeH3c 0.3010322986946989 0.43 0.252\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Connectome Redundancy, R1, and Reachability, S1, vs. fraction of unpaired synapses, fu, Fig 5G\"\"\"\n",
    "\n",
    "undnet = [se01_undi_net,ab01_undi_net,ab02_undi_net]\n",
    "names = ['CeH1c','CeH2c','CeH3c']\n",
    "\n",
    "for net,name in zip(undnet,names):\n",
    "    fu = fractional_asymmetry_undirected(net)[0]\n",
    "    r1,s1 = redundancy_diversity(net,1,directed=False,sex='herm')\n",
    "    print(name,fu,r1,s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Fu</th>\n",
       "      <th>R1</th>\n",
       "      <th>S1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">SR</th>\n",
       "      <th>0.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.104877</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.204938</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.304904</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.404925</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.504150</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.604548</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.704252</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.804427</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.896165</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">ER</th>\n",
       "      <th>0.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.104669</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.204607</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.304997</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.404701</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.504829</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.604794</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.704462</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.804241</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.895445</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">DCB</th>\n",
       "      <th>0.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.104991</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.204710</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.304432</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.404158</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.504476</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.604354</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.704479</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.795116</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.895081</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Fu     R1     S1\n",
       "SR  0.0  0.000000  0.378  0.229\n",
       "    0.1  0.104877  0.358  0.244\n",
       "    0.2  0.204938  0.332  0.273\n",
       "    0.3  0.304904  0.311  0.299\n",
       "    0.4  0.404925  0.293  0.329\n",
       "    0.5  0.504150  0.276  0.359\n",
       "    0.6  0.604548  0.263  0.387\n",
       "    0.7  0.704252  0.252  0.415\n",
       "    0.8  0.804427  0.242  0.447\n",
       "    0.9  0.896165  0.234  0.466\n",
       "    1.0  1.000000  0.225  0.486\n",
       "ER  0.0  0.000000  0.405  0.266\n",
       "    0.1  0.104669  0.382  0.288\n",
       "    0.2  0.204607  0.351  0.314\n",
       "    0.3  0.304997  0.328  0.339\n",
       "    0.4  0.404701  0.305  0.371\n",
       "    0.5  0.504829  0.289  0.406\n",
       "    0.6  0.604794  0.274  0.437\n",
       "    0.7  0.704462  0.262  0.464\n",
       "    0.8  0.804241  0.251  0.496\n",
       "    0.9  0.895445  0.245  0.514\n",
       "    1.0  1.000000  0.235  0.541\n",
       "DCB 0.0  0.000000  0.424  0.260\n",
       "    0.1  0.104991  0.396  0.282\n",
       "    0.2  0.204710  0.368  0.314\n",
       "    0.3  0.304432  0.349  0.338\n",
       "    0.4  0.404158  0.328  0.367\n",
       "    0.5  0.504476  0.311  0.391\n",
       "    0.6  0.604354  0.297  0.419\n",
       "    0.7  0.704479  0.288  0.437\n",
       "    0.8  0.795116  0.272  0.464\n",
       "    0.9  0.895081  0.260  0.486\n",
       "    1.0  1.000000  0.248  0.517"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Generating SR, ER and DCB network'''\n",
    "\n",
    "# Generating SR network\n",
    "ave_edges = np.average([2007,1669,1633])\n",
    "seed = 1317\n",
    "sr_graph = nx.gnm_random_graph(180,ave_edges,seed)\n",
    "sr_graph = nx.relabel_nodes(sr_graph,dict(zip(sr_graph.nodes(),se01_undi_net.nodes())),copy=False)# relabel the SR network nodes with CeH1c node labels\n",
    "\n",
    "# Generating ER network\n",
    "er_grpah = nx.erdos_renyi_graph(len(list(se01_undi_net.nodes())),p=0.124,seed=1319)\n",
    "\n",
    "# Generating the DCB network\n",
    "ref_deg ={t[0]:t[1] for t in nx.degree(se01_undi_net)}\n",
    "\n",
    "# LR_list = pd.read_csv('LR_neurons_separate.csv',header=None)\n",
    "# LR_list = list(LR_list[0])\n",
    "# LR_list_copy = copy.copy(LR_list)\n",
    "dcb_net = nx.Graph()\n",
    "dcb_net.add_nodes_from(se01_undi_net.nodes())\n",
    "\n",
    "asym_edges = {}\n",
    "expected_degrees = list(ref_deg.values())\n",
    "nodelist = list(ref_deg.keys())\n",
    "\n",
    "\n",
    "random.seed(10)\n",
    "random.shuffle(nodelist)\n",
    "i=1\n",
    "for neu,deg in zip(nodelist,expected_degrees):\n",
    "    choice_list = list(set([n for n in nx.neighbors(se11_undi_net,neu)]+[n for n in nx.neighbors(se01_undi_net,neu)]))#\n",
    "    alternate_choice_list = list(nodelist)\n",
    "    j=0\n",
    "    while (nx.degree(dcb_net,neu) < deg) and (j < 180):\n",
    "        if len(choice_list) > 0:\n",
    "            target = random.choice(choice_list)\n",
    "            choice_list.remove(target)\n",
    "        elif len(alternate_choice_list) > 0:\n",
    "            target = alternate_choice_list[j]\n",
    "        if target not in dcb_net.nodes():\n",
    "            dcb_net.add_node(target)\n",
    "        if (not dcb_net.has_edge(neu,target)) and (neu != target) and (dcb_net.degree(target) < list(expected_degrees)[list(nodelist).index(target)]):\n",
    "            dcb_net.add_edge(neu,target)\n",
    "        \n",
    "        j+=1\n",
    "    i+=1\n",
    "\n",
    "\"\"\"Artificial random neural networks ( SR,ER,DCB): Redundancy, R1, and Reachability, S1, vs. fraction of unpaired synapses, fu\"\"\"\n",
    "\n",
    "def return_dict_from_json(filename):\n",
    "    f = open(filename,'r')\n",
    "    dic = json.load(f)\n",
    "    f.close()\n",
    "    return(dic)\n",
    "\n",
    "srdic = return_dict_from_json(folder_path+'/network_files/sr_rand_inst1_s1317.json')\n",
    "erdic = return_dict_from_json(folder_path+'/network_files/er_rand_inst1_s1319.json')\n",
    "dcbdic = return_dict_from_json(folder_path+'/network_files/deg_rand_inst1_s10.json')\n",
    "\n",
    "dic = {}\n",
    "\n",
    "for d,name in zip([srdic,erdic,dcbdic],['SR','ER','DCB']):\n",
    "\n",
    "    for fu in [str(i/10) for i in range(11)]:\n",
    "        net = nx.from_dict_of_lists(d[fu]['net'])\n",
    "        r1,s1 = redundancy_diversity(net,1,directed=False,sex='herm')\n",
    "        rfu = fractional_asymmetry_undirected(net)[0]\n",
    "        inf = {'Fu':rfu,'R1':r1,'S1':s1}\n",
    "        dic[(name,fu)] = inf\n",
    "\n",
    "df = pd.DataFrame.from_dict(dic,orient='columns')\n",
    "df = df.T\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">CeH1c</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CeH2c</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CeH3c</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Fu</th>\n",
       "      <th>R1</th>\n",
       "      <th>S1</th>\n",
       "      <th>Fu</th>\n",
       "      <th>R1</th>\n",
       "      <th>S1</th>\n",
       "      <th>Fu</th>\n",
       "      <th>R1</th>\n",
       "      <th>S1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.104695</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.104882</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.104966</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.204890</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.204037</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.204540</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.304800</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.303942</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.300947</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.396448</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.396159</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.395736</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.495969</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.496322</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.495934</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.595805</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.595487</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.595997</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.695268</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.695279</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.695132</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.795726</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.795439</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.795094</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.895917</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.895477</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.896008</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CeH1c                   CeH2c                   CeH3c              \n",
       "           Fu     R1     S1        Fu     R1     S1        Fu     R1     S1\n",
       "0.0  0.000000  0.502  0.238  0.000000  0.503  0.197  0.000000  0.505  0.185\n",
       "0.1  0.104695  0.469  0.266  0.104882  0.465  0.224  0.104966  0.457  0.217\n",
       "0.2  0.204890  0.433  0.299  0.204037  0.449  0.245  0.204540  0.433  0.243\n",
       "0.3  0.304800  0.414  0.318  0.303942  0.430  0.263  0.300947  0.430  0.252\n",
       "0.4  0.396448  0.394  0.339  0.396159  0.396  0.288  0.395736  0.388  0.278\n",
       "0.5  0.495969  0.358  0.373  0.496322  0.358  0.316  0.495934  0.353  0.306\n",
       "0.6  0.595805  0.328  0.406  0.595487  0.333  0.342  0.595997  0.323  0.336\n",
       "0.7  0.695268  0.303  0.437  0.695279  0.307  0.369  0.695132  0.300  0.367\n",
       "0.8  0.795726  0.284  0.467  0.795439  0.284  0.391  0.795094  0.279  0.399\n",
       "0.9  0.895917  0.269  0.497  0.895477  0.269  0.417  0.896008  0.259  0.432\n",
       "1.0  1.000000  0.255  0.528  1.000000  0.252  0.446  1.000000  0.244  0.461"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Connectome networks: Redundancy, R1, and Reachability, S1, vs. fraction of unpaired synapses, fu, Fig 6D\"\"\"\n",
    "\n",
    "se01dic = return_dict_from_json(folder_path+\"/network_files/se01_undi_symmetrized.json\")\n",
    "ab01dic = return_dict_from_json(folder_path+\"/network_files/ab01_undi_symmetrized.json\")\n",
    "ab02dic = return_dict_from_json(folder_path+\"/network_files/ab02_undi_symmetrized.json\")\n",
    "\n",
    "dic = {}\n",
    "\n",
    "for d,name in zip([se01dic,ab01dic,ab02dic],['CeH1c','CeH2c','CeH3c']):\n",
    "\n",
    "    for fu in [str(i/10) for i in range(11)]:\n",
    "        net = nx.from_dict_of_lists(d[fu]['net'])\n",
    "        r1,s1 = redundancy_diversity(net,1,directed=False,sex='herm')\n",
    "        rfu = fractional_asymmetry_undirected(net)[0]\n",
    "        inf = {'Fu':rfu,'R1':r1,'S1':s1}\n",
    "        dic[(fu,name)] = inf\n",
    "       \n",
    "df = pd.DataFrame.from_dict(dic,orient='index')\n",
    "df = df.T\n",
    "df = df.stack()\n",
    "df = df.swaplevel(0,1)\n",
    "df= df.T\n",
    "df = df.sort_index(axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">0.3</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0.6</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0.9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Fu</th>\n",
       "      <th>R1</th>\n",
       "      <th>S1</th>\n",
       "      <th>Fu</th>\n",
       "      <th>R1</th>\n",
       "      <th>S1</th>\n",
       "      <th>Fu</th>\n",
       "      <th>R1</th>\n",
       "      <th>S1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>0.304323</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.604944</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.895034</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>0.304834</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.604938</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.895803</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>0.304635</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.604757</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.895841</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>0.304954</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.604892</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.896090</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>0.303747</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.604318</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.895702</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>0.304971</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.604944</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.895985</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>0.304503</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.603916</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.897751</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>0.303992</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.604909</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.895521</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>0.304934</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.604972</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.895784</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>0.304507</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.604390</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.896077</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0.3                     0.6                     0.9              \n",
       "            Fu     R1     S1        Fu     R1     S1        Fu     R1     S1\n",
       "1429  0.304323  0.318  0.311  0.604944  0.271  0.388  0.895034  0.237  0.463\n",
       "1430  0.304834  0.314  0.307  0.604938  0.267  0.394  0.895803  0.235  0.476\n",
       "1431  0.304635  0.313  0.297  0.604757  0.270  0.381  0.895841  0.235  0.471\n",
       "1432  0.304954  0.320  0.310  0.604892  0.268  0.400  0.896090  0.240  0.473\n",
       "1433  0.303747  0.305  0.298  0.604318  0.258  0.381  0.895702  0.231  0.463\n",
       "...        ...    ...    ...       ...    ...    ...       ...    ...    ...\n",
       "1624  0.304971  0.313  0.306  0.604944  0.264  0.396  0.895985  0.237  0.478\n",
       "1625  0.304503  0.306  0.305  0.603916  0.262  0.391  0.897751  0.233  0.468\n",
       "1626  0.303992  0.315  0.303  0.604909  0.264  0.383  0.895521  0.234  0.468\n",
       "1627  0.304934  0.310  0.292  0.604972  0.263  0.374  0.895784  0.229  0.464\n",
       "1628  0.304507  0.307  0.310  0.604390  0.262  0.392  0.896077  0.234  0.477\n",
       "\n",
       "[200 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"200 instantitions of artificial simple random network (SR) with distinct fraction of unpaired synapses, fu, 6E\"\"\"\n",
    "\n",
    "sr200 = return_dict_from_json(folder_path+'/network_files/sr_toy200net_large.json')\n",
    "\n",
    "sr200dic = {}\n",
    "\n",
    "for s,d in sr200.items():\n",
    "    for fu in ['0.3', '0.6', '0.9']:\n",
    "        net = nx.from_dict_of_lists(d[fu]['net'])\n",
    "        rfu = fractional_asymmetry_undirected(net)[0]\n",
    "        r1,s1 = redundancy_diversity(net,1,directed=False,sex='herm')\n",
    "        inf = {'Fu':rfu,'R1':r1,'S1':s1}\n",
    "        sr200dic[(s,fu)] = inf\n",
    "\n",
    "df = pd.DataFrame.from_dict(sr200dic,orient='index')\n",
    "df = df.T\n",
    "df = df.stack()\n",
    "df = df.swaplevel(0,1)\n",
    "df= df.T\n",
    "df = df.sort_index(axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">CeH1c</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CeH2c</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CeH3c</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Fu</th>\n",
       "      <th>R1</th>\n",
       "      <th>Rp1</th>\n",
       "      <th>Fu</th>\n",
       "      <th>R1</th>\n",
       "      <th>Rp1</th>\n",
       "      <th>Fu</th>\n",
       "      <th>R1</th>\n",
       "      <th>Rp1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.104695</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.104882</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.104966</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.204890</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.204037</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.204540</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.304800</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.303942</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.300947</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.396448</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.396159</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.395736</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.495969</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.496322</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.495934</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.595805</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.595487</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.595997</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.695268</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.695279</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.695132</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.795726</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.795439</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.795094</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.895917</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.895477</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.896008</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CeH1c                   CeH2c                   CeH3c              \n",
       "           Fu     R1    Rp1        Fu     R1    Rp1        Fu     R1    Rp1\n",
       "0.0  0.000000  0.502  0.502  0.000000  0.503  0.503  0.000000  0.505  0.505\n",
       "0.1  0.104695  0.469  0.413  0.104882  0.465  0.412  0.104966  0.457  0.398\n",
       "0.2  0.204890  0.433  0.334  0.204037  0.449  0.346  0.204540  0.433  0.335\n",
       "0.3  0.304800  0.414  0.287  0.303942  0.430  0.294  0.300947  0.430  0.301\n",
       "0.4  0.396448  0.394  0.239  0.396159  0.396  0.241  0.395736  0.388  0.240\n",
       "0.5  0.495969  0.358  0.183  0.496322  0.358  0.186  0.495934  0.353  0.184\n",
       "0.6  0.595805  0.328  0.136  0.595487  0.333  0.142  0.595997  0.323  0.136\n",
       "0.7  0.695268  0.303  0.095  0.695279  0.307  0.099  0.695132  0.300  0.095\n",
       "0.8  0.795726  0.284  0.059  0.795439  0.284  0.057  0.795094  0.279  0.060\n",
       "0.9  0.895917  0.269  0.029  0.895477  0.269  0.030  0.896008  0.259  0.028\n",
       "1.0  1.000000  0.255  0.000  1.000000  0.252  0.000  1.000000  0.244  0.000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Connectome networks: Redundancy due exclusively to paired synapses, Rp,1, plotted against the fraction of unpaired synapses, fu, Fig 7A\"\"\"\n",
    "se01dic = return_dict_from_json(folder_path+\"/network_files/se01_undi_symmetrized.json\")\n",
    "ab01dic = return_dict_from_json(folder_path+\"/network_files/ab01_undi_symmetrized.json\")\n",
    "ab02dic = return_dict_from_json(folder_path+\"/network_files/ab02_undi_symmetrized.json\")\n",
    "\n",
    "dic = {}\n",
    "\n",
    "for d,name in zip([se01dic,ab01dic,ab02dic],['CeH1c','CeH2c','CeH3c']):\n",
    "    for fu in [str(i/10) for i in range(11)]:\n",
    "        net = nx.from_dict_of_lists(d[fu]['net'])\n",
    "        r1,s1 = redundancy_diversity(net,1,directed=False,sex='herm')\n",
    "        rfu = fractional_asymmetry_undirected(net)[0]\n",
    "        Rp1 = calculate_fuR1fpS1(net,sex='herm',directed=False)[2]\n",
    "        inf = {'Fu':rfu,'R1':r1,'Rp1':Rp1}\n",
    "        dic[(fu,name)] = inf\n",
    "       \n",
    "df = pd.DataFrame.from_dict(dic,orient='index')\n",
    "df = df.T\n",
    "df = df.stack()\n",
    "df = df.swaplevel(0,1)\n",
    "df= df.T\n",
    "df = df.sort_index(axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CeH1c 0.644\n",
      "CeH2c 0.664\n",
      "CeH3c 0.7\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Connectome networks: fraction of Redundancy due only to paired synapses out of total Redundancy , fpR1, Fig 7B\"\"\"\n",
    "undnet = [se01_undi_net,ab01_undi_net,ab02_undi_net]\n",
    "names = ['CeH1c','CeH2c','CeH3c']\n",
    "for net, name in zip(undnet,names):\n",
    "    FpR1 = calculate_fuR1fpS1(net,sex='herm',directed=False)[1]\n",
    "    print(name,FpR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">CeH1c</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CeH2c</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CeH3c</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Fu</th>\n",
       "      <th>S1</th>\n",
       "      <th>Su1</th>\n",
       "      <th>Fu</th>\n",
       "      <th>S1</th>\n",
       "      <th>Su1</th>\n",
       "      <th>Fu</th>\n",
       "      <th>S1</th>\n",
       "      <th>Su1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.104695</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.104882</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.104966</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.204890</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.204037</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.204540</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.304800</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.303942</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.300947</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.396448</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.396159</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.395736</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.495969</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.496322</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.495934</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.595805</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.595487</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.595997</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.695268</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.695279</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.695132</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.795726</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.795439</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.795094</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.895917</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.895477</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.896008</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CeH1c                   CeH2c                   CeH3c              \n",
       "           Fu     S1    Su1        Fu     S1    Su1        Fu     S1    Su1\n",
       "0.0  0.000000  0.238  0.000  0.000000  0.197  0.000  0.000000  0.185  0.000\n",
       "0.1  0.104695  0.266  0.065  0.104882  0.224  0.054  0.104966  0.217  0.059\n",
       "0.2  0.204890  0.299  0.133  0.204037  0.245  0.108  0.204540  0.243  0.111\n",
       "0.3  0.304800  0.318  0.185  0.303942  0.263  0.152  0.300947  0.252  0.146\n",
       "0.4  0.396448  0.339  0.234  0.396159  0.288  0.197  0.395736  0.278  0.189\n",
       "0.5  0.495969  0.373  0.292  0.496322  0.316  0.247  0.495934  0.306  0.240\n",
       "0.6  0.595805  0.406  0.344  0.595487  0.342  0.285  0.595997  0.336  0.283\n",
       "0.7  0.695268  0.437  0.393  0.695279  0.369  0.329  0.695132  0.367  0.329\n",
       "0.8  0.795726  0.467  0.443  0.795439  0.391  0.370  0.795094  0.399  0.373\n",
       "0.9  0.895917  0.497  0.486  0.895477  0.417  0.406  0.896008  0.432  0.418\n",
       "1.0  1.000000  0.528  0.528  1.000000  0.446  0.446  1.000000  0.461  0.461"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Connectome networks: Reachability due exclusively to unpaired synapses, Sp1, plotted against the fraction of unpaired synapses, fu, Fig 7C\"\"\"\n",
    "se01dic = return_dict_from_json(folder_path+\"/network_files/se01_undi_symmetrized.json\")\n",
    "ab01dic = return_dict_from_json(folder_path+\"/network_files/ab01_undi_symmetrized.json\")\n",
    "ab02dic = return_dict_from_json(folder_path+\"/network_files/ab02_undi_symmetrized.json\")\n",
    "\n",
    "dic = {}\n",
    "\n",
    "for d,name in zip([se01dic,ab01dic,ab02dic],['CeH1c','CeH2c','CeH3c']):\n",
    "    for fu in [str(i/10) for i in range(11)]:\n",
    "        net = nx.from_dict_of_lists(d[fu]['net'])\n",
    "        r1,s1 = redundancy_diversity(net,1,directed=False,sex='herm')\n",
    "        rfu = fractional_asymmetry_undirected(net)[0]\n",
    "        Su1 = calculate_fuR1fpS1(net,sex='herm',directed=False)[5]\n",
    "        inf = {'Fu':rfu,'S1':s1,'Su1':Su1}\n",
    "        dic[(fu,name)] = inf\n",
    "       \n",
    "df = pd.DataFrame.from_dict(dic,orient='index')\n",
    "df = df.T\n",
    "df = df.stack()\n",
    "df = df.swaplevel(0,1)\n",
    "df= df.T\n",
    "df = df.sort_index(axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CeH1c 0.652\n",
      "CeH2c 0.611\n",
      "CeH3c 0.578\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Connectome networks: fraction of Redundancy due only to paired synapses out of total Redundancy , fpR1, Fig 7D\"\"\"\n",
    "undnet = [se01_undi_net,ab01_undi_net,ab02_undi_net]\n",
    "names = ['CeH1c','CeH2c','CeH3c']\n",
    "for net, name in zip(undnet,names):\n",
    "    FuS1 = calculate_fuR1fpS1(net,sex='herm',directed=False)[6]\n",
    "\n",
    "    print(name,FuS1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0.0    0.2    0.4    1.0\n",
      "0.051  0.500  0.398  0.346  0.250\n",
      "0.100  0.531  0.419  0.362  0.287\n",
      "0.126  0.523  0.425  0.371  0.295\n",
      "0.200  0.570  0.490  0.415  0.336\n",
      "         0.0    0.2    0.4    1.0\n",
      "0.051  0.100  0.116  0.137  0.211\n",
      "0.100  0.168  0.211  0.258  0.358\n",
      "0.126  0.226  0.279  0.316  0.437\n",
      "0.200  0.337  0.405  0.479  0.611\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Series of small random networks (40 neurons) with variable relative degree, fd, Fig 7E\"\"\"\n",
    "\n",
    "# f = open(folder_path+'/Paper_data/inputs/neuron_lists/class_neuron_count/celegans_class_count_commonSE01AB01AB02.json','r')\n",
    "# LR_class_count = json.load(f)\n",
    "\n",
    "# two_neuron_classes = []\n",
    "# for key,val in LR_class_count.items():\n",
    "#     if val == 2:\n",
    "#         two_neuron_classes.append(key)\n",
    "\n",
    "\n",
    "# LR_classes = pd.read_csv(folder_path+'/Paper_data/inputs/neuron_lists/LR_classes/celegans_LR_neurons_classes_commonSE01AB01AB02.csv',header=None)\n",
    "# LR_classes = list(LR_classes[0])\n",
    "# toy_nodes = []\n",
    "# ex_nodes = []\n",
    "\n",
    "# classes = 20\n",
    "# nodes = classes*2\n",
    "# for label in two_neuron_classes[:classes]:\n",
    "#     for side in ('L','R'):\n",
    "#         toy_nodes.append(str(label)+side)\n",
    "# sr_toy4net_dic = {}\n",
    "\n",
    "\n",
    "# list_of_edges = [40,78,98,156,312,624]\n",
    "# edges_constructed = []\n",
    "# for edges in list_of_edges:\n",
    "#     seed = edges\n",
    "#     while (edges not in edges_constructed):\n",
    "#         random.seed(seed)\n",
    "#         sr_toy = nx.gnm_random_graph(n=nodes,m=edges)\n",
    "#         if (len(sr_toy.nodes()) == nodes) and (len(sr_toy.edges()) == edges) and nx.is_connected(sr_toy):\n",
    "#             print(seed,edges)\n",
    "#             sr_toy = nx.relabel_nodes(sr_toy,dict(zip(sr_toy.nodes(),toy_nodes)),copy=True)\n",
    "#             sr_toy4net_dic['e'+str(edges)+'_s'+str(seed)] = sr_toy\n",
    "#             edges_constructed.append(edges)\n",
    "#         seed+=1\n",
    "\n",
    "toy4R1={'0.0':{},'0.2':{},'0.4':{},'1.0':{}}\n",
    "toy4S1={'0.0':{},'0.2':{},'0.4':{},'1.0':{}}\n",
    "\n",
    "f = open(folder_path+'/network_files/sr_toy4Enet_dic_all.json','r')\n",
    "sr_toy4net_dic_sym_asymed = json.load(f)\n",
    "f.close()\n",
    "\n",
    "for s,dic in sr_toy4net_dic_sym_asymed.items():\n",
    "    dic = {k:v for k,v in dic.items() if v is not None}\n",
    "    \n",
    "    for fu in ['0.0','0.2','0.4','1.0']:\n",
    "        if fu in dic.keys():\n",
    "            net = nx.from_dict_of_lists(dic[fu]['net'])\n",
    "            r1,s1 = redundancy_diversity(net,1,directed=False,sex='herm')\n",
    "            maxedges = (40*39)/2\n",
    "            fd = round(len(net.edges())/maxedges,3)\n",
    "            if fd < 0.25:\n",
    "                toy4R1[fu].update({fd:r1})\n",
    "                toy4S1[fu].update({fd:s1})\n",
    "    \n",
    "toy4R1df = pd.DataFrame.from_dict(toy4R1,orient='index')\n",
    "toy4R1df = toy4R1df.T\n",
    "print(toy4R1df)\n",
    "toy4S1df = pd.DataFrame.from_dict(toy4S1,orient='index')\n",
    "toy4S1df = toy4S1df.T\n",
    "print(toy4S1df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">0.051</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0.100</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0.126</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0.200</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0.400</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0.800</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>R1</th>\n",
       "      <th>S1</th>\n",
       "      <th>fu</th>\n",
       "      <th>R1</th>\n",
       "      <th>S1</th>\n",
       "      <th>fu</th>\n",
       "      <th>R1</th>\n",
       "      <th>S1</th>\n",
       "      <th>fu</th>\n",
       "      <th>R1</th>\n",
       "      <th>S1</th>\n",
       "      <th>fu</th>\n",
       "      <th>R1</th>\n",
       "      <th>S1</th>\n",
       "      <th>fu</th>\n",
       "      <th>R1</th>\n",
       "      <th>S1</th>\n",
       "      <th>fu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.417</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.144365</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.139303</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.131389</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.149078</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.147837</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.148745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.398</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.246032</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.243987</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.246259</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.240030</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.248359</td>\n",
       "      <td>0.803</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.197865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.340714</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.340812</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.348344</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.345074</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.347770</td>\n",
       "      <td>0.799</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.250481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.346</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.439831</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.446806</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.449552</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.449957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.542942</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.545697</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.541126</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.543147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.315</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.609206</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.648771</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.648261</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.646655</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.564575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.287</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.710317</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.746798</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.745119</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.749316</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.654072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.270</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.844048</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.846421</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.845180</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.766659</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.750459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.256</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.870310</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.923931</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.854041</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.851766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.611</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.051                   0.100                   0.126                   \\\n",
       "        R1     S1        fu     R1     S1        fu     R1     S1        fu   \n",
       "0.0  0.500  0.100  0.000000  0.531  0.168  0.000000  0.523  0.226  0.000000   \n",
       "0.1  0.417  0.111  0.144365  0.472  0.189  0.139303  0.506  0.237  0.131389   \n",
       "0.2  0.398  0.116  0.246032  0.419  0.211  0.243987  0.425  0.279  0.246259   \n",
       "0.3  0.375  0.126  0.340714  0.375  0.242  0.340812  0.381  0.311  0.348344   \n",
       "0.4  0.346  0.137  0.420000  0.362  0.258  0.439831  0.371  0.316  0.446806   \n",
       "0.5  0.330  0.147  0.543333  0.335  0.279  0.542942  0.346  0.342  0.545697   \n",
       "0.6  0.315  0.163  0.609206  0.332  0.289  0.648771  0.332  0.368  0.648261   \n",
       "0.7  0.287  0.179  0.710317  0.314  0.311  0.746798  0.330  0.379  0.745119   \n",
       "0.8  0.270  0.195  0.844048  0.292  0.347  0.846421  0.325  0.384  0.845180   \n",
       "0.9  0.256  0.205  0.946667  0.287  0.353  0.870310  0.316  0.400  0.923931   \n",
       "1.0  0.250  0.211  1.000000  0.287  0.358  1.000000  0.295  0.437  1.000000   \n",
       "\n",
       "     0.200                   0.400                   0.800                   \n",
       "        R1     S1        fu     R1     S1        fu     R1     S1        fu  \n",
       "0.0  0.570  0.337  0.000000  0.645  0.616  0.000000  0.831  0.979  0.000000  \n",
       "0.1  0.503  0.395  0.149078  0.573  0.700  0.147837  0.811  0.995  0.148745  \n",
       "0.2  0.490  0.405  0.240030  0.550  0.732  0.248359  0.803  1.000  0.197865  \n",
       "0.3  0.439  0.453  0.345074  0.502  0.800  0.347770  0.799  1.000  0.250481  \n",
       "0.4  0.415  0.479  0.449552  0.472  0.847  0.449957    NaN    NaN       NaN  \n",
       "0.5  0.404  0.495  0.541126  0.469  0.847  0.543147    NaN    NaN       NaN  \n",
       "0.6  0.373  0.537  0.646655  0.463  0.858  0.564575    NaN    NaN       NaN  \n",
       "0.7  0.349  0.574  0.749316  0.451  0.884  0.654072    NaN    NaN       NaN  \n",
       "0.8  0.345  0.579  0.766659  0.430  0.926  0.750459    NaN    NaN       NaN  \n",
       "0.9  0.331  0.600  0.854041  0.436  0.921  0.851766    NaN    NaN       NaN  \n",
       "1.0  0.336  0.611  1.000000    NaN    NaN       NaN    NaN    NaN       NaN  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Series of small random networks (40 neurons) with variable relative degree, fd, Fig S3\"\"\"\n",
    "f = open(folder_path+'/network_files/sr_toy4Enet_dic_all.json','r')\n",
    "sr_toy4net_dic_sym_asymed = json.load(f)\n",
    "f.close()\n",
    "\n",
    "inf = {}\n",
    "for s,dic in sr_toy4net_dic_sym_asymed.items():\n",
    "    dic = {k:v for k,v in dic.items() if v is not None}\n",
    "    \n",
    "    for fu in [str(i/10) for i in range(11)]:\n",
    "        if fu in dic.keys():\n",
    "            net = nx.from_dict_of_lists(dic[fu]['net'])\n",
    "            r1,s1 = redundancy_diversity(net,1,directed=False,sex='herm')\n",
    "            rfu = fractional_asymmetry_undirected(net)[0]\n",
    "            maxedges = (40*39)/2\n",
    "            fd = round(len(net.edges())/maxedges,3)\n",
    "            inf[(fu,fd)] = {'fu':rfu,'R1':r1,'S1':s1}\n",
    "\n",
    "df = pd.DataFrame.from_dict(inf,orient='index')\n",
    "df = df.T\n",
    "df = df.stack()\n",
    "df = df.swaplevel(0,1)\n",
    "df= df.T\n",
    "df = df.sort_index(axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name fd Fu R1 S1\n",
      "SE01 0.125 0.356 0.407 0.328\n",
      "AB01 0.104 0.325 0.431 0.266\n",
      "AB02 0.101 0.301 0.43 0.252\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Connectome networks relative degree, fd, Fig 7F\"\"\"\n",
    "names = ['SE01','AB01','AB02']\n",
    "print('name','fd','Fu','R1','S1')\n",
    "for net,name in zip([se01_undi_net,ab01_undi_net,ab02_undi_net],names):\n",
    "    fu = round(fractional_asymmetry_undirected(net)[0],3)\n",
    "    r1,s1 = redundancy_diversity(net,1,directed=False,sex='herm')\n",
    "    maxedges = (180*179)/2\n",
    "    fd = round(len(net.edges())/maxedges,3)\n",
    "    \n",
    "    print(name,fd,fu,r1,s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "''' Pharynx connectoms'''\n",
    "phadf = pd.read_csv(folder_path+'/raw_data/cne24932-sup-0004-supinfo4.csv',header=[0])\n",
    "phadfchem = phadf.loc[phadf['Type'] == 'Chemical']\n",
    "filter = 'BWM|um|anal|int|sph|vm|mc|hyp|pm|intestine|intL|GLRDL|GLRDR|GLRL|GLRR|GLRLR|GLRVL|GLRVR|excgl|sh|g1|g2|bm|e3D|e3VL|e3VR|RIP'\n",
    "phadfchem = phadfchem[~(phadfchem['Source'].str.contains(filter,regex=True))]\n",
    "phadfchem = phadfchem[~(phadfchem['Target'].str.contains(filter,regex=True))]\n",
    "phachemnet = nx.from_pandas_edgelist(phadfchem,source='Source',target='Target')\n",
    "phadfelec = phadf.loc[phadf['Type'] == 'Electrical']\n",
    "filter = 'BWM|um|anal|int|sph|vm|mc|hyp|pm|intestine|intL|GLRDL|GLRDR|GLRL|GLRR|GLRLR|GLRVL|GLRVR|excgl|sh|g1|g2|bm|e3D|e3VL|e3VR|RIP'\n",
    "phadfelec = phadfelec[~(phadfelec['Source'].str.contains(filter,regex=True))]\n",
    "phadfelec = phadfelec[~(phadfelec['Target'].str.contains(filter,regex=True))]\n",
    "phaelecnet = nx.from_pandas_edgelist(phadfelec,source='Source',target='Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fu</th>\n",
       "      <th>fd</th>\n",
       "      <th>R1</th>\n",
       "      <th>Rp1</th>\n",
       "      <th>S1</th>\n",
       "      <th>Su1</th>\n",
       "      <th>FpR1</th>\n",
       "      <th>FuS1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CeH0c</th>\n",
       "      <td>0.363</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CeH1c</th>\n",
       "      <td>0.356</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CeH2c</th>\n",
       "      <td>0.325</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CeH3c</th>\n",
       "      <td>0.301</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CeH0e</th>\n",
       "      <td>0.499</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CeMc</th>\n",
       "      <td>0.447</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CeMe</th>\n",
       "      <td>0.532</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CeL1c</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CeL2c</th>\n",
       "      <td>0.337</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CeL3c</th>\n",
       "      <td>0.271</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CePc</th>\n",
       "      <td>0.262</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fu     fd     R1    Rp1     S1    Su1   FpR1   FuS1\n",
       "CeH0c  0.363  0.074  0.419  0.270  0.272  0.177  0.644  0.651\n",
       "CeH1c  0.356  0.125  0.407  0.262  0.328  0.214  0.644  0.652\n",
       "CeH2c  0.325  0.104  0.431  0.286  0.266  0.162  0.664  0.611\n",
       "CeH3c  0.301  0.101  0.430  0.301  0.252  0.146  0.700  0.578\n",
       "CeH0e  0.499  0.028  0.339  0.170  0.099  0.075  0.501  0.753\n",
       "CeMc   0.447  0.050  0.388  0.215  0.147  0.101  0.554  0.686\n",
       "CeMe   0.532  0.023  0.325  0.149  0.049  0.035  0.458  0.707\n",
       "CeL1c  0.375  0.048  0.393  0.267  0.136  0.079  0.679  0.582\n",
       "CeL2c  0.337  0.078  0.415  0.285  0.197  0.117  0.687  0.594\n",
       "CeL3c  0.271  0.078  0.434  0.321  0.192  0.100  0.740  0.521\n",
       "CePc   0.262  0.568  0.654  0.462  0.867  0.600  0.706  0.692"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" other connectomes, Fig 8\"\"\"\n",
    "\n",
    "def get_network_from_csv(filename,directed=bool):\n",
    "    df = pd.read_csv(filename,index_col=[0])\n",
    "    if directed:\n",
    "        G = nx.from_pandas_adjacency(df,create_using=nx.DiGraph)\n",
    "        for comp in list(nx.strongly_connected_components(G)):\n",
    "            if len(comp) <3:\n",
    "                for node in comp:\n",
    "                    G.remove_node(node)\n",
    "    elif not directed:\n",
    "        G = nx.from_pandas_adjacency(df,create_using=nx.Graph)\n",
    "        if G is not nx.is_connected(G):\n",
    "            for comp in list(nx.connected_components(G)):\n",
    "                if len(comp) <3:\n",
    "                    for node in comp:\n",
    "                        G.remove_node(node)\n",
    "    return(G)\n",
    "\n",
    "male_chem = get_network_from_csv(folder_path+'/raw_data/male_chemical_connectome_cleaned_c_elegans_no_pharynx.csv',directed=False)\n",
    "male_elec = get_network_from_csv(folder_path+'/raw_data/male_electrical_connectome_cleaned_c_elegans_no_pharynx.csv',directed=False)\n",
    "se00_elec = get_network_from_csv(folder_path+'/raw_data/herm_electrical_connectome_cleaned_c_elegans_no_pharynx.csv',directed=False)\n",
    "\n",
    "def network_info(G,directed=bool,sex=str):\n",
    "    edges = len(G.edges())\n",
    "    nodes = len(G.nodes())\n",
    "    maxedges = (nodes*(nodes-1))/2\n",
    "    fd = edges/maxedges\n",
    "    cc = nx.average_clustering(G)\n",
    "    if not directed:\n",
    "        fu = fractional_asymmetry_undirected(G)[0]\n",
    "        r1,s1 = redundancy_diversity(G,1,directed=False,sex=sex)\n",
    "        fuR1, fpR1, Rp1, fpS1, Sp1, Su1, FuS1 = calculate_fuR1fpS1(G,sex=sex,directed=False)\n",
    "        sp = nx.average_shortest_path_length(G)\n",
    "\n",
    "    return(round(fu,3),round(fd,3),round(r1,3),round(Rp1,3),round(s1,3),round(Su1,3),round(fpR1,3),round(FuS1,3))\n",
    "\n",
    "infodic = {}\n",
    "netlis = [se00_undi_net,se01_undi_net,ab01_undi_net,ab02_undi_net,se00_elec,male_chem,male_elec,l101_undi_net,l201_undi_net,l301_undi_net,phachemnet]\n",
    "name = ['CeH0c','CeH1c','CeH2c','CeH3c','CeH0e','CeMc','CeMe','CeL1c','CeL2c','CeL3c','CePc']\n",
    "for net, name in zip(netlis,name):\n",
    "    if 'M' in name: \n",
    "        Fu,Fd,r1,Rp1,s1,Su1,fpr1,fus1=network_info(net,directed=False,sex='male')\n",
    "        infodic[name] = {'fu':Fu,'fd':Fd,'R1':r1,'Rp1':Rp1,'S1':s1,'Su1':Su1,'FpR1':fpr1,'FuS1':fus1}\n",
    "    else:\n",
    "        Fu,Fd,r1,Rp1,s1,Su1,fpr1,fus1=network_info(net,directed=False,sex='herm')\n",
    "        infodic[name] = {'fu':Fu,'fd':Fd,'R1':r1,'Rp1':Rp1,'S1':s1,'Su1':Su1,'FpR1':fpr1,'FuS1':fus1}\n",
    "infodf = pd.DataFrame.from_dict(infodic,orient='index')\n",
    "infodf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shadow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
